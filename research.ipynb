{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and connect to the IBL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import ibllib.io.video as vidio\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "import umap.umap_ as umap\n",
    "from daart.data import DataGenerator\n",
    "from scipy.interpolate import interp1d\n",
    "from daart.transforms import ZScore\n",
    "from daart.models import Segmenter\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SessionLoader\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from collections import Counter\n",
    "\n",
    "# Connect to the IBL database\n",
    "ONE.setup(base_url='https://openalyx.internationalbrainlab.org', silent=True)\n",
    "one = ONE(password='international')\n",
    "\n",
    "# Load the Model\n",
    "model_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch/version_0'\n",
    "model_file = os.path.join(model_dir, 'best_val_model.pt')\n",
    "\n",
    "hparams_file = os.path.join(model_dir, 'hparams.yaml')\n",
    "hparams = yaml.safe_load(open(hparams_file, 'rb'))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "model = Segmenter(hparams)\n",
    "model.load_state_dict(torch.load(model_file, map_location=lambda storage, loc: storage))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Information (dropbox dataset)\n",
    "dropbox_eids = [\n",
    "    '46794e05-3f6a-4d35-afb3-9165091a5a74',  # churchlandlab/CSHL045/2020-02-27-001\n",
    "    #'c7b0e1a3-4d4d-4a76-9339-e73d0ed5425b',  # cortexlab/KS020/2020-02-06/001 (no trials table)\n",
    "    'db4df448-e449-4a6f-a0e7-288711e7a75a',  # danlab/DY_009/2020-02-27/001\n",
    "    '54238fd6-d2d0-4408-b1a9-d19d24fd29ce',  # danlab_DY_018_2020-10-15-001\n",
    "    'f3ce3197-d534-4618-bf81-b687555d1883',  # hoferlab_SWC_043_2020-09-15-001\n",
    "    '493170a6-fd94-4ee4-884f-cc018c17eeb9',  # hoferlab_SWC_061_2020-11-23-001\n",
    "    '7cb81727-2097-4b52-b480-c89867b5b34c',  # mrsicflogellab_SWC_052_2020-10-22-001\n",
    "    #'1735d2be-b388-411a-896a-60b01eaa1cfe',  # mrsicflogellab_SWC_058_2020-12-11-001 (no trials table)\n",
    "    'ff96bfe1-d925-4553-94b5-bf8297adf259',  # wittenlab/ibl_witten_26/2021-01-27-002\n",
    "    '73918ae1-e4fd-4c18-b132-00cb555b1ad2',  # wittenlab_ibl_witten_27_2021-01-21-001\n",
    "]\n",
    "\n",
    "dropbox_marker_paths = {\n",
    "    '46794e05-3f6a-4d35-afb3-9165091a5a74': 'churchlandlab_CSHL045_2020-02-27-001',\n",
    "    'c7b0e1a3-4d4d-4a76-9339-e73d0ed5425b': 'cortexlab_KS020_2020-02-06-001',\n",
    "    'db4df448-e449-4a6f-a0e7-288711e7a75a': 'danlab_DY_009_2020-02-27-001',\n",
    "    '54238fd6-d2d0-4408-b1a9-d19d24fd29ce': 'danlab_DY_018_2020-10-15-001',\n",
    "    'f3ce3197-d534-4618-bf81-b687555d1883': 'hoferlab_SWC_043_2020-09-15-001',\n",
    "    '493170a6-fd94-4ee4-884f-cc018c17eeb9': 'hoferlab_SWC_061_2020-11-23-001',\n",
    "    '7cb81727-2097-4b52-b480-c89867b5b34c': 'mrsicflogellab_SWC_052_2020-10-22-001',\n",
    "    '1735d2be-b388-411a-896a-60b01eaa1cfe': 'mrsicflogellab_SWC_058_2020-12-11-001',\n",
    "    'ff96bfe1-d925-4553-94b5-bf8297adf259': 'wittenlab_ibl_witten_26_2021-01-27-002',\n",
    "    '73918ae1-e4fd-4c18-b132-00cb555b1ad2': 'wittenlab_ibl_witten_27_2021-01-21-001'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create data generator\n",
    "def create_data_generator(sess_id, input_file):    \n",
    "    signals = ['markers']\n",
    "    transforms = [ZScore()]\n",
    "    paths = [input_file]\n",
    "\n",
    "    return DataGenerator(\n",
    "        [sess_id], [signals], [transforms], [paths],\n",
    "        batch_size=hparams['batch_size'], sequence_length=hparams['sequence_length'], sequence_pad=hparams['sequence_pad'],\n",
    "        trial_splits=hparams['trial_splits'], input_type=hparams['input_type'],\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run inference\n",
    "def get_states(model, data_gen):\n",
    "    tmp = model.predict_labels(data_gen, return_scores=True)\n",
    "    probs = np.vstack(tmp['labels'][0])\n",
    "    return np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average durations\n",
    "def calculate_average_durations(states):\n",
    "    unique_states = [0, 1, 2, 3, 4]\n",
    "    average_durations = []\n",
    "\n",
    "    for state in unique_states:\n",
    "        durations = []\n",
    "        current_duration = 0\n",
    "        in_segment = False\n",
    "\n",
    "        for s in states:\n",
    "            if s == state:\n",
    "                if in_segment:\n",
    "                    current_duration += 1\n",
    "                else:\n",
    "                    in_segment = True\n",
    "                    current_duration = 1\n",
    "            else:\n",
    "                if in_segment:\n",
    "                    durations.append(current_duration)\n",
    "                    in_segment = False\n",
    "\n",
    "        # Append the last segment duration if it ended with the last element\n",
    "        if in_segment:\n",
    "            durations.append(current_duration)\n",
    "\n",
    "        if durations:\n",
    "            average_durations.append(np.mean(durations))\n",
    "        else:\n",
    "            average_durations.append(0)\n",
    "\n",
    "    return average_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to Perform Smoothing\n",
    "def non_uniform_savgol(x, y, window, polynom):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError('\"x\" and \"y\" must be of the same size')\n",
    "    if len(x) < window:\n",
    "        raise ValueError('The data size must be larger than the window size')\n",
    "    if type(window) is not int:\n",
    "        raise TypeError('\"window\" must be an integer')\n",
    "    if window % 2 == 0:\n",
    "        raise ValueError('The \"window\" must be an odd integer')\n",
    "    if type(polynom) is not int:\n",
    "        raise TypeError('\"polynom\" must be an integer')\n",
    "    if polynom >= window:\n",
    "        raise ValueError('\"polynom\" must be less than \"window\"')\n",
    "\n",
    "    half_window = window // 2\n",
    "    polynom += 1\n",
    "\n",
    "    A = np.empty((window, polynom))\n",
    "    tA = np.empty((polynom, window))\n",
    "    t = np.empty(window)\n",
    "    y_smoothed = np.full(len(y), np.nan)\n",
    "\n",
    "    for i in range(half_window, len(x) - half_window, 1):\n",
    "        x0 = x[i]\n",
    "        A[:, 0] = 1.0\n",
    "        for j in range(1, polynom):\n",
    "            A[:, j] = (x[i - half_window:i + half_window + 1] - x0)**j\n",
    "        tA = A.T\n",
    "        t = np.linalg.inv(tA @ A) @ tA @ y[i - half_window:i + half_window + 1]\n",
    "        y_smoothed[i] = t[0]\n",
    "\n",
    "    y_smoothed[:half_window + 1] = y[:half_window + 1]\n",
    "    y_smoothed[-half_window - 1:] = y[-half_window - 1:]\n",
    "\n",
    "    return y_smoothed\n",
    "\n",
    "# Function to smooth and interpolate the marker signals\n",
    "def smooth_interpolate_signal_sg(signal, window=31, order=3, interp_kind='linear'):\n",
    "\n",
    "    signal_noisy_w_nans = np.copy(signal)\n",
    "    timestamps = np.arange(signal_noisy_w_nans.shape[0])\n",
    "    good_idxs = np.where(~np.isnan(signal_noisy_w_nans))[0]\n",
    "    if len(good_idxs) < window:\n",
    "        print('Not enough non-nan indices to filter; returning original signal')\n",
    "        return signal_noisy_w_nans\n",
    "    signal_smooth_nonans = non_uniform_savgol(\n",
    "        timestamps[good_idxs], signal_noisy_w_nans[good_idxs], window=window, polynom=order)\n",
    "    signal_smooth_w_nans = np.copy(signal_noisy_w_nans)\n",
    "    signal_smooth_w_nans[good_idxs] = signal_smooth_nonans\n",
    "    interpolater = interp1d(\n",
    "        timestamps[good_idxs], signal_smooth_nonans, kind=interp_kind, fill_value='extrapolate')\n",
    "    signal = interpolater(timestamps)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and/or smooth ibl data\n",
    "def extract_marker_data(eid, l_thresh, view, paw, smooth):\n",
    "    #sess_id = dropbox_marker_paths[eid]\n",
    "\n",
    "    # Load the pose data\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()  \n",
    "\n",
    "    # Load wheel data\n",
    "    sl.load_wheel()\n",
    "    wh_times = sl.wheel.times.to_numpy()\n",
    "    wh_vel_oversampled = sl.wheel.velocity.to_numpy()\n",
    "    \n",
    "    # Resample wheel data at marker times\n",
    "    interpolator = interp1d(wh_times, wh_vel_oversampled, fill_value='extrapolate')\n",
    "    wh_vel = interpolator(times)\n",
    "\n",
    "    if smooth == True:\n",
    "        # Smooth the marker data\n",
    "        markers[:, 0] = smooth_interpolate_signal_sg(markers[:, 0], window=7)\n",
    "        markers[:, 1] = smooth_interpolate_signal_sg(markers[:, 1], window=7)\n",
    "        \n",
    "    # Process the data\n",
    "    markers_comb = np.hstack([markers, wh_vel[:, None]])\n",
    "    velocity = np.vstack([np.array([0, 0, 0]), np.diff(markers_comb, axis=0)])\n",
    "    markers_comb = np.hstack([markers_comb, velocity])\n",
    "    markers_z = (markers_comb - np.mean(markers_comb, axis=0)) / np.std(markers_comb, axis=0)\n",
    "    feature_names = ['paw_x_pos', 'paw_y_pos', 'wheel_vel', 'paw_x_vel', 'paw_y_vel', 'wheel_acc']\n",
    "    df = pd.DataFrame(markers_z, columns=feature_names)\n",
    "\n",
    "    if smooth == False:\n",
    "        df.to_csv(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/daart/features/{eid}_features.csv')\n",
    "        markers_file = f'/Users/zacharyzusin/Documents/NeuroscienceResearch/daart/features/{eid}_features.csv'\n",
    "    else:\n",
    "        df.to_csv(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/daart/features/{eid}_features_smooth.csv')\n",
    "        markers_file = f'/Users/zacharyzusin/Documents/NeuroscienceResearch/daart/features/{eid}_features_smooth.csv'\n",
    "    return markers_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a heatmap of the predicted states\n",
    "def create_predicted_states_heatmap(eid, data_dict):\n",
    "    # Convert eid to sess_id internally\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    \n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Create a custom color palette\n",
    "    cmap = sns.color_palette(\"tab10\", n_colors=4)\n",
    "    \n",
    "    # Combine the datasets if multiple are provided\n",
    "    if len(data_dict) > 1:\n",
    "        data = np.vstack([data_dict[key] for key in data_dict.keys()])\n",
    "        yticklabels = list(data_dict.keys())\n",
    "    else:\n",
    "        key = list(data_dict.keys())[0]\n",
    "        data = data_dict[key]\n",
    "        yticklabels = [key]\n",
    "        \n",
    "        # Ensure data is reshaped to be a 2D array\n",
    "        if len(data.shape) == 1:\n",
    "            data = data.reshape(1, -1)\n",
    "    \n",
    "    # Calculate F1 scores if multiple datasets are provided\n",
    "    f1_scores = None\n",
    "    if len(data_dict) > 1:\n",
    "        f1_scores = {}\n",
    "        keys = list(data_dict.keys())\n",
    "        for i in range(len(keys)):\n",
    "            for j in range(i + 1, len(keys)):\n",
    "                key1, key2 = keys[i], keys[j]\n",
    "                f1 = f1_score(data_dict[key1], data_dict[key2], average='macro')\n",
    "                f1_scores[f'{key1} vs {key2}'] = f1\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(data, cmap=cmap, cbar=True, yticklabels=yticklabels, annot=False)\n",
    "    \n",
    "    # Customize the colorbar\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    colorbar.set_ticks([1.375, 2.125, 2.875, 3.625])\n",
    "    colorbar.set_ticklabels(state_labels)\n",
    "    \n",
    "    plt.title(f'Heatmap of Discrete States for {sess_id}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Source')\n",
    "    \n",
    "    if f1_scores:\n",
    "        f1_text = '\\n\\n\\n' + 'F1 Scores: ' + ', '.join([f'{key}: {f1:.2f}' for key, f1 in f1_scores.items()])\n",
    "        plt.text(0.5, -0.1, f1_text, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_heatmap_states.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a plot of the frequency of each state\n",
    "def create_state_frequency_plot(eid, data_dict):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    \n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Initialize lists to store state counts for each dataset\n",
    "    unique_states = [1, 2, 3, 4]\n",
    "    state_counts = {key: [np.sum(data_dict[key] == state) for state in unique_states] for key in data_dict}\n",
    "    \n",
    "    # Create a DataFrame for easier plotting\n",
    "    df = pd.DataFrame({'State': state_labels})\n",
    "    for key in data_dict:\n",
    "        df[key] = state_counts[key]\n",
    "\n",
    "    # Plot the histogram\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    width = 0.25  # the width of the bars\n",
    "\n",
    "    # Position of the bars on the x-axis\n",
    "    r_positions = np.arange(len(state_labels)) * (len(data_dict) + 1) * width\n",
    "\n",
    "    # Create bars for each dataset\n",
    "    for i, key in enumerate(data_dict):\n",
    "        r = [x + i * width for x in r_positions]\n",
    "        ax.bar(r, df[key], width=width, edgecolor='grey', label=key)\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    ax.set_xlabel('States', fontweight='bold')\n",
    "    ax.set_ylabel('Frames', fontweight='bold')\n",
    "    ax.set_title(f'Time Spent in Each State for {sess_id}', fontweight='bold')\n",
    "    ax.set_xticks([r + width * (len(data_dict) - 1) / 2 for r in r_positions])\n",
    "    ax.set_xticklabels(state_labels)\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_state_frequency.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a plot of the average duration spent in each state\n",
    "def create_state_duration_plot(eid, data_dict):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    \n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Initialize lists to store average durations for each dataset\n",
    "    avg_durations = {key: calculate_average_durations(data_dict[key])[1:] for key in data_dict}\n",
    "    \n",
    "    # Create a DataFrame for easier plotting\n",
    "    df = pd.DataFrame({'State': state_labels})\n",
    "    for key in data_dict:\n",
    "        df[key] = avg_durations[key]\n",
    "\n",
    "    # Plot the average durations\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    width = 0.25  # the width of the bars\n",
    "\n",
    "    # Position of the bars on the x-axis\n",
    "    r_positions = np.arange(len(state_labels)) * (len(data_dict) + 1) * width\n",
    "\n",
    "    # Create bars for each dataset\n",
    "    for i, key in enumerate(data_dict):\n",
    "        r = [x + i * width for x in r_positions]\n",
    "        ax.bar(r, df[key], width=width, edgecolor='grey', label=key)\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    ax.set_xlabel('States', fontweight='bold')\n",
    "    ax.set_ylabel('Frames', fontweight='bold')\n",
    "    ax.set_title(f'Average Time Spent in Each State for {sess_id}', fontweight='bold')\n",
    "    ax.set_xticks([r + width * (len(data_dict) - 1) / 2 for r in r_positions])\n",
    "    ax.set_xticklabels(state_labels)\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_state_duration.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create video with predictions overlayed\n",
    "def create_video_comparing_predictions(eid, states_dropbox_truncated, states_ibl_truncated, states_ibl_smooth_truncated):\n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Load the video\n",
    "    label = 'left'\n",
    "    url = vidio.url_from_eid(eid, one=one)[label]\n",
    "\n",
    "    video_path = url #'/Users/zacharyzusin/Documents/NeuroscienceResearch/dropbox/videos/' + sess_id + '.mp4'\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Define the output video path and create directory\n",
    "    output_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch/video_analysis/dataset_comparison_videos'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, dropbox_marker_paths[eid] + '_three_datasets.mp4')\n",
    "\n",
    "    def overlay_predictions(frame, frame_num, dropbox_pred, ibl_pred, ibl_smooth_pred):\n",
    "        # Create a figure and axis\n",
    "        fig = Figure(figsize=(10, 6))\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax = fig.gca()\n",
    "\n",
    "        # Display the video frame\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Add text for predictions\n",
    "        ax.text(10, 30, f\"Dropbox: {state_labels[dropbox_pred-1]}\", color='white', fontsize=12, bbox=dict(facecolor='blue', alpha=0.5))\n",
    "        ax.text(10, 60, f\"IBL: {state_labels[ibl_pred-1]}\", color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "        ax.text(10, 90, f\"IBL Smooth: {state_labels[ibl_smooth_pred-1]}\", color='white', fontsize=12, bbox=dict(facecolor='green', alpha=0.5))\n",
    "\n",
    "        # Add frame number\n",
    "        ax.text(10, frame.shape[0] - 10, f\"Frame: {frame_num}\", color='white', fontsize=12)\n",
    "\n",
    "        # Remove axes\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Convert to image\n",
    "        canvas.draw()\n",
    "        image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 30.0, (1000, 600))\n",
    "\n",
    "    for i in range(1000):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Overlay predictions\n",
    "        frame_with_pred = overlay_predictions(frame, i, states_dropbox_truncated[i], states_ibl_truncated[i], states_ibl_smooth_truncated[i])\n",
    "\n",
    "        # Write frame\n",
    "        out.write(cv2.cvtColor(frame_with_pred, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video creation completed. Check '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create video with trial markers\n",
    "def create_video_with_trial_markers(eid, states_ibl_smooth,  l_thresh, view, paw):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    \n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Load the video\n",
    "    label = 'left'\n",
    "    video_path = vidio.url_from_eid(eid, one=one)[label]\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the frame rate of the video\n",
    "    input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the output video path and create directory\n",
    "    output_dir = f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, dropbox_marker_paths[eid] + '_predictions.mp4')\n",
    "\n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, input_fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    # Function to overlay predictions, paw markers, and trial number on each frame of the video\n",
    "    def overlay_predictions(frame, frame_num, ibl_smooth_pred=None, trial_number=None, text=None, paw_position=None):\n",
    "        # Add text for prediction if ibl_smooth_pred is not None\n",
    "        if ibl_smooth_pred is not None:\n",
    "            cv2.putText(frame, f\"IBL Smooth: {state_labels[int(ibl_smooth_pred)-1]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Add frame number\n",
    "        cv2.putText(frame, f\"Frame: {frame_num}\", (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Add \"Trial n\" text at the center of the frame if trial_number is not None\n",
    "        if trial_number is not None:\n",
    "            trial_text = f\"Trial {trial_number}\"\n",
    "            textsize = cv2.getTextSize(trial_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "            textX = (frame.shape[1] - textsize[0]) // 2\n",
    "            textY = (frame.shape[0] + textsize[1]) // 2\n",
    "            cv2.putText(frame, trial_text, (textX, textY), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Add additional text if provided\n",
    "        if text is not None:\n",
    "            textsize = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "            textX = (frame.shape[1] - textsize[0]) // 2\n",
    "            textY = 50  # Top of the frame\n",
    "            cv2.putText(frame, text, (textX, textY), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Add paw marker if provided and not NaN\n",
    "        if paw_position is not None:\n",
    "            if not np.isnan(paw_position[0]) and not np.isnan(paw_position[1]):\n",
    "                cv2.circle(frame, (int(paw_position[0]), int(paw_position[1])), 15, (0, 0, 255), -1)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    # Load trial event times\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    trial_end_times = trials['intervals'][:, 1]\n",
    "    stim_on_times = trials['stimOn_times']\n",
    "    first_movement_times = trials['firstMovement_times']\n",
    "    response_times = trials['response_times']\n",
    "    feedback_types = trials['feedbackType']\n",
    "\n",
    "    # Convert times to frame indices\n",
    "    trial_start_frame_indices = (trial_start_times * input_fps).astype(int)\n",
    "    trial_end_frame_indices = (trial_end_times * input_fps).astype(int)\n",
    "    stim_on_frame_indices = (stim_on_times * input_fps).astype(int)\n",
    "    first_movement_frame_indices = (first_movement_times * input_fps).astype(int)\n",
    "    response_frame_indices = (response_times * input_fps).astype(int)\n",
    "\n",
    "    # Get user input for specific trials or ranges of trials\n",
    "    # Example input: \"1,3-5,10\" for trials 1, 3 to 5, and 10 or \"All\" for all trials\n",
    "    user_input = input(\"Enter trial numbers or ranges (e.g., '1,3-5,10' or 'All'): \")\n",
    "\n",
    "    if user_input.strip().lower() == 'all':\n",
    "        trial_numbers = list(range(1, len(trial_start_times) + 1))\n",
    "    else:\n",
    "        trial_numbers = []\n",
    "        for part in user_input.split(','):\n",
    "            if '-' in part:\n",
    "                start, end = map(int, part.split('-'))\n",
    "                trial_numbers.extend(range(start, end + 1))\n",
    "            else:\n",
    "                trial_numbers.append(int(part))\n",
    "        \n",
    "    # Get the corresponding frame ranges for the specified trials\n",
    "    trial_frame_ranges = []\n",
    "    end_frame = 0\n",
    "    for trial_num in trial_numbers:\n",
    "        trial_index = trial_num - 1\n",
    "        if trial_index < len(trial_start_frame_indices):\n",
    "            start_frame = trial_start_frame_indices[trial_index]\n",
    "            end_frame = trial_end_frame_indices[trial_index]\n",
    "            trial_frame_ranges.append((start_frame, end_frame))\n",
    "\n",
    "    # Load paw markers\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh, views=[view])\n",
    "    paw_positions = sl.pose[f'{view}Camera'].loc[:, [f'{paw}_x', f'{paw}_y']].to_numpy()\n",
    "\n",
    "    # Iterate through each specified trial frame range\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for start_frame, end_frame in trial_frame_ranges:\n",
    "        frame_num = start_frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        while frame_num <= end_frame and frame_num < frame_count:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame is None:\n",
    "                print(f\"Skipping frame {frame_num} due to read error.\")\n",
    "                frame_num += 1\n",
    "                continue\n",
    "\n",
    "            # Determine the trial number from trial_start_frame_indices\n",
    "            trial_number_index = np.where(trial_start_frame_indices == start_frame)[0]\n",
    "            if trial_number_index.size > 0:\n",
    "                trial_number = trial_number_index[0] + 1\n",
    "\n",
    "                if frame_num == start_frame:\n",
    "                    # Insert a one-second screen with trial number\n",
    "                    for _ in range(int(input_fps)):\n",
    "                        frame_with_pred = overlay_predictions(np.zeros_like(frame), frame_num, trial_number=trial_number)\n",
    "                        out.write(frame_with_pred)\n",
    "\n",
    "                text = None\n",
    "                if frame_num in stim_on_frame_indices:\n",
    "                    text = \"Stimulus Onset\"\n",
    "                elif frame_num in first_movement_frame_indices:\n",
    "                    text = \"First Movement Detected\"\n",
    "                elif frame_num in response_frame_indices:\n",
    "                    response_index = np.where(response_frame_indices == frame_num)[0][0]\n",
    "                    feedback = feedback_types[response_index]\n",
    "                    text = f\"Response Recorded: {'Positive' if feedback == 1 else 'Negative'}\"\n",
    "\n",
    "                paw_pos = paw_positions[frame_num] if frame_num < len(paw_positions) else None\n",
    "\n",
    "                if frame_num < len(states_ibl_smooth):\n",
    "                    frame_with_pred = overlay_predictions(frame, frame_num, states_ibl_smooth[frame_num], text=text, paw_position=paw_pos)\n",
    "                else:\n",
    "                    frame_with_pred = overlay_predictions(frame, frame_num, text=text, paw_position=paw_pos)\n",
    "\n",
    "                out.write(frame_with_pred)\n",
    "\n",
    "            frame_num += 1\n",
    "\n",
    "            if frame_num % 1000 == 0:\n",
    "                print(f\"Processed frame {frame_num}/{frame_count}\")\n",
    "\n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video creation completed. Check '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a heatmap of the wheel speed aligned to movement onset\n",
    "def create_wheel_speed_heatmap(eid, l_thresh, view, paw):    \n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "\n",
    "    # Load times\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    \n",
    "    # Load marker data\n",
    "    file = extract_marker_data(eid, l_thresh, view, paw, smooth=True)\n",
    "    df = pd.read_csv(file)\n",
    "    wh_vel = df['wheel_vel'].to_numpy()\n",
    "    wh_speed = np.abs(wh_vel)\n",
    "\n",
    "    # Load first movement times\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    first_movement_times = trials['firstMovement_times']\n",
    "\n",
    "    # Define the window around movement onset\n",
    "    window = (-0.2, 1.0)  # 200 ms before to 1000 ms after movement onset\n",
    "    num_frames = int((window[1] - window[0]) * 60)  # 60 Hz sampling rate\n",
    "\n",
    "    # Initialize array to hold aligned wheel velocities\n",
    "    aligned_wheel_vel = np.zeros((150, num_frames))\n",
    "\n",
    "    for i, onset in enumerate(first_movement_times[:150]):\n",
    "        mask = (times >= (onset + window[0])) & (times <= (onset + window[1]))\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        \n",
    "        onset_times = times[mask] - onset\n",
    "        onset_wheel_vel = wh_speed[mask]\n",
    "\n",
    "        # Interpolate to have a consistent number of frames\n",
    "        interp_times = np.linspace(window[0], window[1], num_frames)\n",
    "        interp_wheel_vel = np.interp(interp_times, onset_times, onset_wheel_vel)\n",
    "        aligned_wheel_vel[i, :] = interp_wheel_vel\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(aligned_wheel_vel, cmap='coolwarm', cbar_kws={'label': 'Wheel Speed (radians per second)'})\n",
    "    plt.axvline(x=num_frames * -window[0] / (window[1] - window[0]), color='k', linestyle='--')\n",
    "    plt.xlabel('Time (frames)')\n",
    "    plt.ylabel('Trial')\n",
    "    plt.title(f'Wheel Speed Aligned to Movement Onset for {sess_id}')\n",
    "    plt.show()\n",
    "    fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/figures/{sess_id}_wheel_speed_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a heatmap of the predicted states aligned to a specified trial event\n",
    "def create_states_aligned_heatmap(eid, l_thresh, view, paw, align_event='firstMovement_times', split_by_feedback=False):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "\n",
    "    # State labels\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    \n",
    "    # Load times\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    \n",
    "    # Load marker data\n",
    "    file = extract_marker_data(eid, l_thresh, view, paw, smooth=True)\n",
    "    \n",
    "    # Load trial data\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    trial_end_times = trials['intervals'][:, 1]\n",
    "    align_times = trials[align_event]\n",
    "    feedback_types = trials['feedbackType']\n",
    "\n",
    "    data_gen = create_data_generator(sess_id, file)\n",
    "    states_ibl_smooth = get_states(model, data_gen)\n",
    "    states_ibl_smooth = np.clip(states_ibl_smooth, 1, 4)\n",
    "\n",
    "    # Create a custom color palette\n",
    "    cmap = sns.color_palette(\"tab10\", n_colors=4)\n",
    "    \n",
    "    # Align states to the specified event\n",
    "    aligned_states_correct = []\n",
    "    aligned_states_incorrect = []\n",
    "    skipped_trials = []\n",
    "    pre_time = 0.5  # 500 ms before the alignment event\n",
    "    post_time = 2.0  # 2000 ms after the alignment event\n",
    "    sampling_rate = 1 / np.median(np.diff(times))  # Approximate sampling rate (Hz)\n",
    "    pre_frames = int(pre_time * sampling_rate)\n",
    "    post_frames = int(post_time * sampling_rate)\n",
    "    max_length = int((pre_time + post_time) * 60)  # 60 Hz sampling rate\n",
    "\n",
    "    for i, align_time in enumerate(align_times):\n",
    "        start_time = align_time - pre_time\n",
    "        end_time = align_time + post_time\n",
    "        start_idx = np.searchsorted(times, start_time)\n",
    "        end_idx = np.searchsorted(times, end_time)\n",
    "        align_idx = np.searchsorted(times, align_time)\n",
    "        \n",
    "        trial_states = states_ibl_smooth[start_idx:end_idx]\n",
    "        align_offset = align_idx - start_idx\n",
    "\n",
    "        # Convert to float array\n",
    "        trial_states = trial_states.astype(float)\n",
    "\n",
    "        # Pad or truncate to ensure same length\n",
    "        if len(trial_states) < max_length:\n",
    "            pad_len = max_length - len(trial_states)\n",
    "            trial_states = np.pad(trial_states, (0, pad_len), mode='constant', constant_values=np.nan)\n",
    "        elif len(trial_states) > max_length:\n",
    "            trial_states = trial_states[:max_length]\n",
    "\n",
    "        # Apply mask for time points outside of the trial\n",
    "        trial_mask = np.full(max_length, False)\n",
    "        trial_duration_mask = (times[start_idx:end_idx] >= trial_start_times[i]) & (times[start_idx:end_idx] <= trial_end_times[i])\n",
    "        min_len = min(len(trial_duration_mask), len(trial_mask))\n",
    "        trial_mask[:min_len] = trial_duration_mask[:min_len]\n",
    "        trial_states[~trial_mask] = np.nan\n",
    "\n",
    "        if np.all(np.isnan(trial_states)):\n",
    "            skipped_trials.append((i, \"All NaNs after alignment\"))\n",
    "        else:\n",
    "            if split_by_feedback:\n",
    "                if feedback_types[i] == 1:\n",
    "                    aligned_states_correct.append((trial_states, align_offset))\n",
    "                else:\n",
    "                    aligned_states_incorrect.append((trial_states, align_offset))\n",
    "            else:\n",
    "                aligned_states_correct.append((trial_states, align_offset))\n",
    "\n",
    "    # Convert list of tuples to 2D NumPy arrays\n",
    "    aligned_states_correct_array = np.full((len(aligned_states_correct), max_length), np.nan)\n",
    "    for i, (trial_states, align_offset) in enumerate(aligned_states_correct):\n",
    "        aligned_states_correct_array[i, :len(trial_states)] = trial_states\n",
    "    \n",
    "    if split_by_feedback:\n",
    "        aligned_states_incorrect_array = np.full((len(aligned_states_incorrect), max_length), np.nan)\n",
    "        for i, (trial_states, align_offset) in enumerate(aligned_states_incorrect):\n",
    "            aligned_states_incorrect_array[i, :len(trial_states)] = trial_states\n",
    "\n",
    "    # Print skipped trials and reasons\n",
    "    for trial_idx, reason in skipped_trials:\n",
    "        print(f\"Skipped trial {trial_idx}: {reason}\")\n",
    "\n",
    "    # Plot the heatmap for correct trials\n",
    "    fig_correct = plt.figure(figsize=(15, 10))\n",
    "    ax_correct = sns.heatmap(aligned_states_correct_array, cmap=cmap, cbar=True, yticklabels=np.arange(1, len(aligned_states_correct_array) + 1, 20), annot=False)\n",
    "\n",
    "    # Customize the colorbar\n",
    "    colorbar_correct = ax_correct.collections[0].colorbar\n",
    "    colorbar_correct.set_ticks([1.375, 2.125, 2.875, 3.625])\n",
    "    colorbar_correct.set_ticklabels(state_labels)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    ticks = np.linspace(0, max_length, num=6)\n",
    "    ticklabels = np.round(np.linspace(-pre_time, post_time, num=6), 2)\n",
    "    ax_correct.set_xticks(ticks)\n",
    "    ax_correct.set_xticklabels(ticklabels)\n",
    "    \n",
    "    # Set y-axis ticks and labels (trial numbers)\n",
    "    ax_correct.set_yticks(np.arange(0, len(aligned_states_correct_array), 50) + 0.5)\n",
    "    ax_correct.set_yticklabels(np.arange(0, len(aligned_states_correct_array), 50))\n",
    "\n",
    "    plt.title(f'Aligned Discrete States for {sess_id} (Correct Trials)')\n",
    "    plt.xlabel(f'Time (seconds) relative to {align_event}')\n",
    "    plt.ylabel('Trial')\n",
    "    plt.axvline(x=pre_frames, color='k', linestyle='--', linewidth=1)\n",
    "    plt.show()\n",
    "    fig_correct.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_{align_event}_aligned_heatmap_correct.png')\n",
    "\n",
    "    # Plot the heatmap for incorrect trials (if splitting by feedback)\n",
    "    if split_by_feedback:\n",
    "        fig_incorrect = plt.figure(figsize=(15, 10))\n",
    "        ax_incorrect = sns.heatmap(aligned_states_incorrect_array, cmap=cmap, cbar=True, yticklabels=np.arange(1, len(aligned_states_incorrect_array) + 1, 20), annot=False)\n",
    "\n",
    "        # Customize the colorbar\n",
    "        colorbar_incorrect = ax_incorrect.collections[0].colorbar\n",
    "        colorbar_incorrect.set_ticks([1.375, 2.125, 2.875, 3.625])\n",
    "        colorbar_incorrect.set_ticklabels(state_labels)\n",
    "\n",
    "        # Set x-axis ticks and labels\n",
    "        ax_incorrect.set_xticks(ticks)\n",
    "        ax_incorrect.set_xticklabels(ticklabels)\n",
    "        \n",
    "        # Set y-axis ticks and labels (trial numbers)\n",
    "        ax_incorrect.set_yticks(np.arange(0, len(aligned_states_incorrect_array), 50) + 0.5)\n",
    "        ax_incorrect.set_yticklabels(np.arange(0, len(aligned_states_incorrect_array), 50))\n",
    "\n",
    "        plt.title(f'Aligned Discrete States for {sess_id} (Incorrect Trials)')\n",
    "        plt.xlabel(f'Time (seconds) relative to {align_event}')\n",
    "        plt.ylabel('Trial')\n",
    "        plt.axvline(x=pre_frames, color='k', linestyle='--', linewidth=1)\n",
    "        plt.show()\n",
    "        fig_incorrect.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_{align_event}_aligned_heatmap_incorrect.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a plot of the length of each trial interval (stim onset to first movement, first movement to response; response to trial end)\n",
    "def create_trial_interval_plot(eid):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "\n",
    "    # Load trial data\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    stim_on_times = trials['stimOn_times']\n",
    "    first_movement_times = trials['firstMovement_times']\n",
    "    response_times = trials['response_times']\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    trial_end_times = trials['intervals'][:, 1]\n",
    "    \n",
    "    # Calculate the lengths of each trial interval\n",
    "    stim_to_first_movement = first_movement_times - stim_on_times\n",
    "    first_movement_to_response = response_times - first_movement_times\n",
    "    response_to_end = trial_end_times - response_times\n",
    "\n",
    "    # Remove NaN values before calculating the average durations\n",
    "    stim_to_first_movement = stim_to_first_movement[np.isfinite(stim_to_first_movement)]\n",
    "    first_movement_to_response = first_movement_to_response[np.isfinite(first_movement_to_response)]\n",
    "    response_to_end = response_to_end[np.isfinite(response_to_end)]\n",
    "\n",
    "    # Calculate the average durations\n",
    "    avg_stim_to_first_movement = np.mean(stim_to_first_movement)\n",
    "    avg_first_movement_to_response = np.mean(first_movement_to_response)\n",
    "    avg_response_to_end = np.mean(response_to_end)\n",
    "\n",
    "    # Create a DataFrame for easier plotting\n",
    "    data = {\n",
    "        'Interval': ['Stimulus to First Movement', 'First Movement to Response', 'Response to Trial End'],\n",
    "        'Average Duration (s)': [avg_stim_to_first_movement, avg_first_movement_to_response, avg_response_to_end]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Plot using DataFrame\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df.plot(kind='bar', x='Interval', y='Average Duration (s)', ax=ax, edgecolor='grey', legend=False)\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_title(f'Average Trial Interval Durations for session {sess_id}', fontweight='bold')\n",
    "    ax.set_xlabel('Intervals', fontweight='bold')\n",
    "    ax.set_ylabel('Seconds', fontweight='bold')\n",
    "    ax.set_ylim(0, df['Average Duration (s)'].max() * 1.1)  # Add some space above the highest bar\n",
    "\n",
    "    # Adjust x-axis labels\n",
    "    ax.tick_params(axis='x', labelrotation=0)  # Set rotation to 0 for horizontal labels\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_trial_intervals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Loop\n",
    "save_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch'\n",
    "\n",
    "l_thresh = 0.0\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "if view == 'right':\n",
    "    raise NotImplementedError\n",
    "\n",
    "for eid in eids:\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    print(f'Eid: {eid} -- Session: {sess_id}')\n",
    "\n",
    "    # Extract the marker data from the ibl database\n",
    "    #ibl_markers_file = extract_marker_data(eid, l_thresh, view, paw, smooth=False)\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh, view, paw, smooth=False)\n",
    "\n",
    "    # Dropbox Data\n",
    "    #dropbox_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch/dropbox'\n",
    "    #dropbox_markers_file = os.path.join(dropbox_dir, 'features-posvel', sess_id + '_labeled.csv')\n",
    "\n",
    "    # Build the Data Generators\n",
    "    #data_gen_dropbox = create_data_generator(sess_id, dropbox_markers_file)\n",
    "    #data_gen_ibl = create_data_generator(sess_id, ibl_markers_file)\n",
    "    #data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "\n",
    "    # Run Inference\n",
    "    #states_dropbox = get_states(model, data_gen_dropbox)\n",
    "    #states_ibl = get_states(model, data_gen_ibl)\n",
    "    #states_ibl_smooth = get_states(model, data_gen_ibl_smooth)\n",
    "\n",
    "    # Ensure state values are within the correct range\n",
    "    #states_dropbox = np.clip(states_dropbox, 1, 4)\n",
    "    #states_ibl = np.clip(states_ibl, 1, 4)\n",
    "    #states_ibl_smooth = np.clip(states_ibl_smooth, 1, 4)\n",
    "\n",
    "    # Truncate the arrays to match the length of the shortest one\n",
    "    #min_length = min(len(states_dropbox), len(states_ibl), len(states_ibl_smooth))\n",
    "    #states_dropbox_truncated = states_dropbox[:min_length]\n",
    "    #states_ibl_truncated = states_ibl[:min_length]\n",
    "    #states_ibl_smooth_truncated = states_ibl_smooth[:min_length]\n",
    "    \n",
    "    #data_dict = {'Dropbox States': states_dropbox_truncated, 'IBL States': states_ibl_truncated, 'IBL Smooth States': states_ibl_smooth_truncated}\n",
    "    #data_dict = {'IBL Smooth States': states_ibl_smooth}\n",
    "\n",
    "    # Create a predicted state heatmap\n",
    "    #create_predicted_states_heatmap(eid, data_dict)\n",
    "\n",
    "    # Create a state frequency plot\n",
    "    #create_state_frequency_plot(eid, data_dict)\n",
    "\n",
    "    # Create a state duration plot\n",
    "    #create_state_duration_plot(eid, data_dict)\n",
    "\n",
    "    # Create a video with predictions overlayed\n",
    "    #create_video_comparing_predictions(eid, states_dropbox_truncated, states_ibl_truncated, states_ibl_smooth_truncated)\n",
    "\n",
    "    # Create a video with trial markers\n",
    "    #create_video_with_trial_markers(eid, states_ibl_smooth, l_thresh_smooth, view, paw)\n",
    "\n",
    "    # Create a wheel speed heatmap\n",
    "    #create_wheel_speed_heatmap(eid, l_thresh_smooth, view, paw)\n",
    "\n",
    "    # Create a heatmap of the predicted states aligned to the first movement times\n",
    "    #create_first_movement_aligned_heatmap(eid, l_thresh_smooth, view, paw)\n",
    "\n",
    "    # Create a heatmap of the predicted states aligned to trial event times (which include 'goCueTrigger_times', 'stimOff_times', 'response_times', 'goCue_times', 'firstMovement_times', 'stimOn_times' and 'feedback_times')\n",
    "    #create_states_aligned_heatmap(eid, l_thresh_smooth, view, paw, align_event='response_times', split_by_feedback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Information (rephro-ephys)\n",
    "eids = [\n",
    "    'db4df448-e449-4a6f-a0e7-288711e7a75a',  # Berkeley\n",
    "    'd23a44ef-1402-4ed7-97f5-47e9a7a504d9',  # Berkeley\n",
    "    '4a45c8ba-db6f-4f11-9403-56e06a33dfa4',  # Berkeley\n",
    "    'e535fb62-e245-4a48-b119-88ce62a6fe67',  # Berkeley\n",
    "    '54238fd6-d2d0-4408-b1a9-d19d24fd29ce',  # Berkeley\n",
    "    'b03fbc44-3d8e-4a6c-8a50-5ea3498568e0',  # Berkeley\n",
    "    '30c4e2ab-dffc-499d-aae4-e51d6b3218c2',  # CCU\n",
    "    'd0ea3148-948d-4817-94f8-dcaf2342bbbe',  # CCU\n",
    "    'a4a74102-2af5-45dc-9e41-ef7f5aed88be',  # CCU\n",
    "    '746d1902-fa59-4cab-b0aa-013be36060d5',  # CCU\n",
    "    '88224abb-5746-431f-9c17-17d7ef806e6a',  # CCU\n",
    "    '0802ced5-33a3-405e-8336-b65ebc5cb07c',  # CCU\n",
    "    'ee40aece-cffd-4edb-a4b6-155f158c666a',  # CCU\n",
    "    'c7248e09-8c0d-40f2-9eb4-700a8973d8c8',  # CCU\n",
    "    '72cb5550-43b4-4ef0-add5-e4adfdfb5e02',  # CCU\n",
    "    'dda5fc59-f09a-4256-9fb5-66c67667a466',  # CSHL(C)\n",
    "    '4b7fbad4-f6de-43b4-9b15-c7c7ef44db4b',  # CSHL(C)\n",
    "    'f312aaec-3b6f-44b3-86b4-3a0c119c0438',  # CSHL(C)\n",
    "    '4b00df29-3769-43be-bb40-128b1cba6d35',  # CSHL(C)\n",
    "    'ecb5520d-1358-434c-95ec-93687ecd1396',  # CSHL(C)\n",
    "    '51e53aff-1d5d-4182-a684-aba783d50ae5',  # NYU\n",
    "    'f140a2ec-fd49-4814-994a-fe3476f14e66',  # NYU\n",
    "    'a8a8af78-16de-4841-ab07-fde4b5281a03',  # NYU\n",
    "    '61e11a11-ab65-48fb-ae08-3cb80662e5d6',  # NYU\n",
    "    '73918ae1-e4fd-4c18-b132-00cb555b1ad2',  # Princeton\n",
    "    'd9f0c293-df4c-410a-846d-842e47c6b502',  # Princeton\n",
    "    'dac3a4c1-b666-4de0-87e8-8c514483cacf',  # SWC(H)\n",
    "    '6f09ba7e-e3ce-44b0-932b-c003fb44fb89',  # SWC(H)\n",
    "    '56b57c38-2699-4091-90a8-aba35103155e',  # SWC(M)\n",
    "    '3638d102-e8b6-4230-8742-e548cd87a949',  # SWC(M)\n",
    "    '7cb81727-2097-4b52-b480-c89867b5b34c',  # SWC(M)\n",
    "    '781b35fd-e1f0-4d14-b2bb-95b7263082bb',  # UCL\n",
    "    '3f859b5c-e73a-4044-b49e-34bb81e96715',  # UCL\n",
    "    'b22f694e-4a34-4142-ab9d-2556c3487086',  # UCL\n",
    "    '0a018f12-ee06-4b11-97aa-bbbff5448e9f',  # UCL\n",
    "    'aad23144-0e52-4eac-80c5-c4ee2decb198',  # UCL\n",
    "    'b196a2ad-511b-4e90-ac99-b5a29ad25c22',  # UCL\n",
    "    'e45481fa-be22-4365-972c-e7404ed8ab5a',  # UCL\n",
    "    'd04feec7-d0b7-4f35-af89-0232dd975bf0',  # UCL\n",
    "    '1b715600-0cbc-442c-bd00-5b0ac2865de1',  # UCL\n",
    "    'c7bf2d49-4937-4597-b307-9f39cb1c7b16',  # UCL\n",
    "    '8928f98a-b411-497e-aa4b-aa752434686d',  # UCL\n",
    "    'ebce500b-c530-47de-8cb1-963c552703ea',  # UCLA\n",
    "    'dc962048-89bb-4e6a-96a9-b062a2be1426',  # UCLA\n",
    "    '6899a67d-2e53-4215-a52a-c7021b5da5d4',  # UCLA\n",
    "    '15b69921-d471-4ded-8814-2adad954bcd8',  # UCLA\n",
    "    '5ae68c54-2897-4d3a-8120-426150704385',  # UCLA\n",
    "    'ca4ecb4c-4b60-4723-9b9e-2c54a6290a53',  # UCLA\n",
    "    '824cf03d-4012-4ab1-b499-c83a92c5589e',  # UCLA\n",
    "    '3bcb81b4-d9ca-4fc9-a1cd-353a966239ca',  # UW\n",
    "    'f115196e-8dfe-4d2a-8af3-8206d93c1729',  # UW\n",
    "    '9b528ad0-4599-4a55-9148-96cc1d93fb24',  # UW\n",
    "    '3e6a97d3-3991-49e2-b346-6948cb4580fb',  # UW\n",
    "]\n",
    "\n",
    "dropbox_marker_paths = {\n",
    "    'db4df448-e449-4a6f-a0e7-288711e7a75a': 'danlab_DY_009_2020-02-27-001',\n",
    "    'd23a44ef-1402-4ed7-97f5-47e9a7a504d9': 'danlab_DY_016_2020-09-12-001',\n",
    "    '4a45c8ba-db6f-4f11-9403-56e06a33dfa4': 'danlab_DY_020_2020-09-29-001',\n",
    "    'e535fb62-e245-4a48-b119-88ce62a6fe67': 'danlab_DY_013_2020-03-12-001',\n",
    "    '54238fd6-d2d0-4408-b1a9-d19d24fd29ce': 'danlab_DY_018_2020-10-15-001',\n",
    "    'b03fbc44-3d8e-4a6c-8a50-5ea3498568e0': 'danlab_DY_010_2020-01-27-001',\n",
    "    '30c4e2ab-dffc-499d-aae4-e51d6b3218c2': 'mainenlab_ZFM-02370_2021-04-29-001',\n",
    "    'd0ea3148-948d-4817-94f8-dcaf2342bbbe': 'mainenlab_ZFM-01936_2021-01-19-001',\n",
    "    'a4a74102-2af5-45dc-9e41-ef7f5aed88be': 'mainenlab_ZFM-02368_2021-06-01-001',\n",
    "    '746d1902-fa59-4cab-b0aa-013be36060d5': 'mainenlab_ZFM-01592_2020-10-20-001',\n",
    "    '88224abb-5746-431f-9c17-17d7ef806e6a': 'mainenlab_ZFM-02372_2021-06-01-002',\n",
    "    '0802ced5-33a3-405e-8336-b65ebc5cb07c': 'mainenlab_ZFM-02373_2021-06-23-001',\n",
    "    'ee40aece-cffd-4edb-a4b6-155f158c666a': 'mainenlab_ZM_2241_2020-01-30-001',\n",
    "    'c7248e09-8c0d-40f2-9eb4-700a8973d8c8': 'mainenlab_ZM_3001_2020-08-05-001',\n",
    "    '72cb5550-43b4-4ef0-add5-e4adfdfb5e02': 'mainenlab_ZFM-02369_2021-05-19-001',\n",
    "    'dda5fc59-f09a-4256-9fb5-66c67667a466': 'churchlandlab_CSHL059_2020-03-06-001',\n",
    "    '4b7fbad4-f6de-43b4-9b15-c7c7ef44db4b': 'churchlandlab_CSHL049_2020-01-08-001',\n",
    "    'f312aaec-3b6f-44b3-86b4-3a0c119c0438': 'churchlandlab_CSHL058_2020-07-07-001',\n",
    "    '4b00df29-3769-43be-bb40-128b1cba6d35': 'churchlandlab_CSHL052_2020-02-21-001',\n",
    "    'ecb5520d-1358-434c-95ec-93687ecd1396': 'churchlandlab_CSHL051_2020-02-05-001',\n",
    "    '51e53aff-1d5d-4182-a684-aba783d50ae5': 'angelakilab_NYU-45_2021-07-19-001',\n",
    "    'f140a2ec-fd49-4814-994a-fe3476f14e66': 'angelakilab_NYU-47_2021-06-21-003',\n",
    "    'a8a8af78-16de-4841-ab07-fde4b5281a03': 'angelakilab_NYU-12_2020-01-22-001',\n",
    "    '61e11a11-ab65-48fb-ae08-3cb80662e5d6': 'angelakilab_NYU-21_2020-08-10-002',\n",
    "    '73918ae1-e4fd-4c18-b132-00cb555b1ad2': 'wittenlab_ibl_witten_27_2021-01-21-001',\n",
    "    'd9f0c293-df4c-410a-846d-842e47c6b502': 'wittenlab_ibl_witten_25_2020-12-07-002',\n",
    "    'dac3a4c1-b666-4de0-87e8-8c514483cacf': 'hoferlab_SWC_060_2020-11-24-001',\n",
    "    '6f09ba7e-e3ce-44b0-932b-c003fb44fb89': 'hoferlab_SWC_043_2020-09-16-002',\n",
    "    '56b57c38-2699-4091-90a8-aba35103155e': 'mrsicflogellab_SWC_054_2020-10-05-001',\n",
    "    '3638d102-e8b6-4230-8742-e548cd87a949': 'mrsicflogellab_SWC_058_2020-12-07-001',\n",
    "    '7cb81727-2097-4b52-b480-c89867b5b34c': 'mrsicflogellab_SWC_052_2020-10-22-001',\n",
    "    '781b35fd-e1f0-4d14-b2bb-95b7263082bb': 'cortexlab_KS044_2020-12-09-001',\n",
    "    '3f859b5c-e73a-4044-b49e-34bb81e96715': 'cortexlab_KS094_2022-06-17-001',\n",
    "    'b22f694e-4a34-4142-ab9d-2556c3487086': 'cortexlab_KS055_2021-05-02-001',\n",
    "    '0a018f12-ee06-4b11-97aa-bbbff5448e9f': 'cortexlab_KS051_2021-05-11-001',\n",
    "    'aad23144-0e52-4eac-80c5-c4ee2decb198': 'cortexlab_KS023_2019-12-10-001',\n",
    "    'b196a2ad-511b-4e90-ac99-b5a29ad25c22': 'cortexlab_KS084_2022-02-01-001',\n",
    "    'e45481fa-be22-4365-972c-e7404ed8ab5a': 'cortexlab_KS086_2022-03-15-001',\n",
    "    'd04feec7-d0b7-4f35-af89-0232dd975bf0': 'cortexlab_KS089_2022-03-19-001',\n",
    "    '1b715600-0cbc-442c-bd00-5b0ac2865de1': 'cortexlab_KS084_2022-01-31-001',\n",
    "    'c7bf2d49-4937-4597-b307-9f39cb1c7b16': 'cortexlab_KS074_2021-11-22-001',\n",
    "    '8928f98a-b411-497e-aa4b-aa752434686d': 'cortexlab_KS096_2022-06-17-001',\n",
    "    'ebce500b-c530-47de-8cb1-963c552703ea': 'churchlandlab_ucla_MFD_09_2023-10-19-001',\n",
    "    'dc962048-89bb-4e6a-96a9-b062a2be1426': 'churchlandlab_ucla_UCLA048_2022-08-16-001',\n",
    "    '6899a67d-2e53-4215-a52a-c7021b5da5d4': 'churchlandlab_ucla_MFD_06_2023-08-29-001',\n",
    "    '15b69921-d471-4ded-8814-2adad954bcd8': 'churchlandlab_ucla_MFD_07_2023-08-31-001',\n",
    "    '5ae68c54-2897-4d3a-8120-426150704385': 'churchlandlab_ucla_MFD_08_2023-09-07-001',\n",
    "    'ca4ecb4c-4b60-4723-9b9e-2c54a6290a53': 'churchlandlab_ucla_MFD_05_2023-08-16-001',\n",
    "    '824cf03d-4012-4ab1-b499-c83a92c5589e': 'churchlandlab_ucla_UCLA011_2021-07-20-001',\n",
    "    '3bcb81b4-d9ca-4fc9-a1cd-353a966239ca': 'steinmetzlab_NR_0024_2023-01-19-001',\n",
    "    'f115196e-8dfe-4d2a-8af3-8206d93c1729': 'steinmetzlab_NR_0021_2022-06-23-003',\n",
    "    '9b528ad0-4599-4a55-9148-96cc1d93fb24': 'steinmetzlab_NR_0019_2022-04-29-001',\n",
    "    '3e6a97d3-3991-49e2-b346-6948cb4580fb': 'steinmetzlab_NR_0020_2022-05-08-001',\n",
    "    #dropbox dataset sessions follow\n",
    "    '46794e05-3f6a-4d35-afb3-9165091a5a74': 'churchlandlab_CSHL045_2020-02-27-001',\n",
    "    'db4df448-e449-4a6f-a0e7-288711e7a75a': 'danlab_DY_009_2020-02-27-001',\n",
    "    '54238fd6-d2d0-4408-b1a9-d19d24fd29ce': 'danlab_DY_018_2020-10-15-001',\n",
    "    'f3ce3197-d534-4618-bf81-b687555d1883': 'hoferlab_SWC_043_2020-09-15-001',\n",
    "    '493170a6-fd94-4ee4-884f-cc018c17eeb9': 'hoferlab_SWC_061_2020-11-23-001',\n",
    "    '7cb81727-2097-4b52-b480-c89867b5b34c': 'mrsicflogellab_SWC_052_2020-10-22-001',\n",
    "    'ff96bfe1-d925-4553-94b5-bf8297adf259': 'wittenlab_ibl_witten_26_2021-01-27-002',\n",
    "    '73918ae1-e4fd-4c18-b132-00cb555b1ad2': 'wittenlab_ibl_witten_27_2021-01-21-001'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethogram graphing functions\n",
    "palette = sns.color_palette(\"tab10\", n_colors=4)\n",
    "cmap = ListedColormap(palette.as_hex())\n",
    "\n",
    "def graph_etho_img(fig, states, markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start=0, length=600):\n",
    "    n_rows = 2\n",
    "    outer_grid = gridspec.GridSpec(n_rows, 1, figure=fig, height_ratios=[.2, .8])\n",
    "    axes = [fig.add_subplot(outer_grid[i]) for i in range(n_rows)]\n",
    "\n",
    "    n_classes = np.max(states)  # Determine the number of classes from states\n",
    "\n",
    "    # Graph DAART model predictions\n",
    "    data = states[start:(start+length)]\n",
    "    graph_states(axes[0], data, n_classes)\n",
    "    axes[0].set(ylabel=\"DAART\")\n",
    "    axes[0].yaxis.label.set(rotation='horizontal', ha='right')\n",
    "\n",
    "    # Graph markers\n",
    "    markers = markers[start:(start+length)]  # Use markers as is\n",
    "    graph_markers(axes[1], markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start=start)\n",
    "\n",
    "    # Add a legend for the states\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    state_colors = sns.color_palette(\"tab10\", n_colors=4)\n",
    "    handles = [Patch(facecolor=color, edgecolor='k', label=label) for color, label in zip(state_colors, state_labels)]\n",
    "    axes[0].legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Set x-axis label\n",
    "    axes[1].set_xlabel('Time (frames)', fontsize=12)\n",
    "\n",
    "def graph_states(ax, states, n_classes):\n",
    "    n_frames = states.shape[0]\n",
    "    im = ax.imshow(\n",
    "        states[None, :], aspect='auto', \n",
    "        cmap=cmap, interpolation='none',\n",
    "        vmin=1, vmax=n_classes)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def graph_markers(ax, markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start):\n",
    "    # Calculate min and max values for each marker\n",
    "    y_min = np.min(markers, axis=0)\n",
    "    y_max = np.max(markers, axis=0)\n",
    "    \n",
    "    # Define regions for each marker\n",
    "    num_markers = len(m_inds)\n",
    "    height = 1.0 \n",
    "    y_offsets = np.arange(num_markers) * height\n",
    "    \n",
    "    for idx, m_idx in enumerate(m_inds):\n",
    "        marker_data = markers[:, m_idx]\n",
    "        norm_marker_data = (marker_data - y_min[m_idx]) / (y_max[m_idx] - y_min[m_idx]) * height\n",
    "        ax.plot(np.arange(len(marker_data)) + start, norm_marker_data + y_offsets[idx], color='k', linewidth=2)\n",
    "    \n",
    "    # Add vertical lines for all instances of trial start, go cue, and feedback times within the range\n",
    "    ax.vlines(trial_start_times[(trial_start_times >= start) & (trial_start_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='r', linestyle='--')\n",
    "    ax.vlines(go_cue_times[(go_cue_times >= start) & (go_cue_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='b', linestyle='--')\n",
    "    ax.vlines(feedback_times[(feedback_times >= start) & (feedback_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='g', linestyle='--')\n",
    "    \n",
    "    # Create legend handles for each event type\n",
    "    handles = [\n",
    "        Patch(color='r', linestyle='--', label='Trial Start'),\n",
    "        Patch(color='b', linestyle='--', label='Go Cue'),\n",
    "        Patch(color='g', linestyle='--', label='Feedback')\n",
    "    ]\n",
    "    \n",
    "    # Set x-axis limits and ticks\n",
    "    end = start + len(markers)\n",
    "    ax.set_xlim([start, end])\n",
    "    \n",
    "    num_ticks = 6\n",
    "    tick_positions = np.linspace(start, end, num_ticks).astype(int)\n",
    "    tick_labels = np.linspace(start, end, num_ticks).astype(int)\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    \n",
    "    ax.spines[['right', 'left']].set_visible(False)\n",
    "    ax.set_yticks(y_offsets + height / 2)\n",
    "    ax.set_yticklabels(marker_names)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Camera Loop\n",
    "save_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch'\n",
    "l_thresh_smooth = 0.9\n",
    "views = ['left', 'right']\n",
    "paws = ['paw_r', 'paw_l']\n",
    "\n",
    "for eid in eids[:1]:\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    print(f'Eid: {eid} -- Session: {sess_id}')\n",
    "\n",
    "    # Load the pose data\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh_smooth, views=views)\n",
    "\n",
    "    # Load the left camera view\n",
    "    left_signal = sl.pose[f'{views[0]}Camera'].loc[:, (f'{paws[0]}_x', f'{paws[0]}_y')].to_numpy()\n",
    "    left_timestamps = sl.pose[f'{views[0]}Camera'].times.to_numpy()\n",
    "\n",
    "    # Load the right camera view\n",
    "    right_signal = sl.pose[f'{views[1]}Camera'].loc[:, (f'{paws[1]}_x', f'{paws[1]}_y')].to_numpy()\n",
    "    right_timestamps = sl.pose[f'{views[1]}Camera'].times.to_numpy()\n",
    "\n",
    "    # Interpolate the right signal to match the left timestamps\n",
    "    interpolator = interp1d(right_timestamps, right_signal, axis=0, kind='linear', fill_value='extrapolate')\n",
    "    right_signal_interpolated = interpolator(left_timestamps)\n",
    "\n",
    "    # Flip x coordinates for the right paw and z-score\n",
    "    right_signal_interpolated_flipped = 640 - right_signal_interpolated  # Assuming width of 640\n",
    "    right_signal_interpolated_zscored = (right_signal_interpolated_flipped - np.mean(right_signal_interpolated_flipped, axis=0)) / np.std(right_signal_interpolated_flipped, axis=0)\n",
    "    \n",
    "    # Load wheel data and resample at marker times\n",
    "    sl.load_wheel()\n",
    "    wheel_velocity_signal = sl.wheel.velocity.to_numpy()\n",
    "    wheel_velocity_timestamps = sl.wheel.times.to_numpy()\n",
    "    wheel_velocity_interpolator = interp1d(wheel_velocity_timestamps, wheel_velocity_signal, kind='linear', fill_value='extrapolate')\n",
    "    wheel_velocity_interpolated = wheel_velocity_interpolator(left_timestamps)\n",
    "\n",
    "    # Process the data\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "    states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "\n",
    "    view = 'left'\n",
    "    paw = 'paw_r'\n",
    "    create_video_with_trial_markers(eid, states_ibl_smooth, l_thresh_smooth, view, paw)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create histograms of time spent in states during different periods of the trial\n",
    "def create_histograms(eid, states_ibl_smooth):\n",
    "    #sess_id = dropbox_marker_paths[eid]\n",
    "    input_fps = 60\n",
    "    \n",
    "    # Load trial event times\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    trial_end_times = trials['intervals'][:, 1]\n",
    "    first_movement_times = trials['firstMovement_times']\n",
    "    feedback_times = trials['feedback_times']\n",
    "\n",
    "    # Convert times to frame indices\n",
    "    trial_start_frame_indices = (trial_start_times * input_fps).astype(int)\n",
    "    trial_end_frame_indices = (trial_end_times * input_fps).astype(int)\n",
    "    first_movement_frame_indices = (first_movement_times * input_fps).astype(int)\n",
    "    feedback_frame_indices = (feedback_times * input_fps).astype(int)\n",
    "\n",
    "    # Define bin edges (in seconds) for histograms\n",
    "    bin_edges = [0, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 5, np.inf]\n",
    "    bin_labels = ['0-25 ms', '25-50 ms', '50-100 ms', '100-200 ms', '200-300 ms', '300-400 ms', '400-500 ms', '0.5-1 s', '1-2 s', '2-5 s', '5+ s']\n",
    "    \n",
    "    def calculate_time_in_state(frame_indices, states):\n",
    "        time_in_state = np.zeros((len(trial_start_times), 4))\n",
    "        for i, (start, end) in enumerate(frame_indices):\n",
    "            trial_states = states[start:end]\n",
    "            for state in range(4):\n",
    "                time_in_state[i, state] = np.sum(trial_states == state + 1) / input_fps\n",
    "        return time_in_state\n",
    "    \n",
    "    # Calculate time in each state for both periods\n",
    "    time_in_state_first_to_feedback = calculate_time_in_state(\n",
    "        zip(first_movement_frame_indices, feedback_frame_indices),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "    time_in_state_feedback_to_end = calculate_time_in_state(\n",
    "        zip(feedback_frame_indices, trial_end_frame_indices),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "\n",
    "    def plot_histogram(data, period, state_labels):\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axes = axes.flatten()\n",
    "        for state in range(4):\n",
    "            state_data = data[:, state]\n",
    "            hist, _ = np.histogram(state_data, bins=bin_edges)\n",
    "            hist = hist / len(trial_start_times)\n",
    "            axes[state].bar(bin_labels, hist, align='center')\n",
    "            axes[state].set_title(f'{state_labels[state]}')\n",
    "            axes[state].set_xlabel('Time spent in state')\n",
    "            axes[state].set_ylabel('Proportion of trials')\n",
    "            axes[state].set_xticklabels(bin_labels, rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'State Distribution during {period} for Session {sess_id}', y=1.05, fontsize=16)\n",
    "        plt.show()\n",
    "        fig.savefig(f'/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis/{sess_id}/{sess_id}_state_distribution_{period}.png')\n",
    "\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "\n",
    "    plot_histogram(time_in_state_first_to_feedback, 'first movement to feedback', state_labels)\n",
    "    plot_histogram(time_in_state_feedback_to_end, 'feedback to trial end', state_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Clustering\n",
    "\n",
    "def calculate_time_in_state(frame_indices, states, input_fps=60):\n",
    "    time_in_state = np.zeros((len(frame_indices), 4))\n",
    "    for i, (start, end) in enumerate(frame_indices):\n",
    "        trial_states = states[start:end]\n",
    "        for state in range(4):\n",
    "            time_in_state[i, state] = np.sum(trial_states == state + 1) / input_fps # Convert frames to seconds\n",
    "    return time_in_state\n",
    "\n",
    "def get_proportions(eid):\n",
    "    input_fps = 60\n",
    "\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    data_gen_ibl_smooth = create_data_generator(eid, ibl_smooth_markers_file)\n",
    "    states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "    # Load trial event times\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    trial_end_times = trials['intervals'][:, 1]\n",
    "    first_movement_times = trials['firstMovement_times']\n",
    "    feedback_times = trials['feedback_times']\n",
    "\n",
    "    # Convert times to frame indices\n",
    "    trial_start_frame_indices = (trial_start_times * input_fps).astype(int)\n",
    "    trial_end_frame_indices = (trial_end_times * input_fps).astype(int)\n",
    "    first_movement_frame_indices = (first_movement_times * input_fps).astype(int)\n",
    "    feedback_frame_indices = (feedback_times * input_fps).astype(int)\n",
    "\n",
    "    # Calculate time in each state for both periods\n",
    "    time_in_state_first_to_feedback = calculate_time_in_state(\n",
    "        list(zip(first_movement_frame_indices, feedback_frame_indices)),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "    time_in_state_feedback_to_end = calculate_time_in_state(\n",
    "        list(zip(feedback_frame_indices, trial_end_frame_indices)),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "\n",
    "    # Define bin edges (in seconds) for histograms\n",
    "    bin_edges = [0, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 5, np.inf]\n",
    "\n",
    "    # Compute histograms\n",
    "    histograms = np.zeros((2, 4, len(bin_edges) - 1))\n",
    "    for state in range(4):\n",
    "        hist_first_to_feedback, _ = np.histogram(time_in_state_first_to_feedback[:, state], bins=bin_edges)\n",
    "        hist_feedback_to_end, _ = np.histogram(time_in_state_feedback_to_end[:, state], bins=bin_edges)\n",
    "        histograms[0, state] = hist_first_to_feedback / len(trial_start_times)\n",
    "        histograms[1, state] = hist_feedback_to_end / len(trial_start_times)\n",
    "\n",
    "    # Flatten the histograms to create the 88-dim vector\n",
    "    proportions = histograms.flatten()\n",
    "\n",
    "    return proportions\n",
    "\n",
    "def process_sessions_and_umap(eids, dropbox_eids):\n",
    "    input_fps = 60\n",
    "\n",
    "    # Combine the eids and dropbox_eids\n",
    "    all_eids = eids + dropbox_eids\n",
    "    \n",
    "    # Get the data\n",
    "    data = np.array([get_proportions(eid) for eid in all_eids])\n",
    "    \n",
    "    # Create labels for the groups\n",
    "    labels = ['Standard'] * len(eids) + ['Dropbox'] * len(dropbox_eids)\n",
    "    \n",
    "    # Apply UMAP to reduce to 2D\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    embedding = reducer.fit_transform(data)\n",
    "\n",
    "    # Create a DataFrame for easier handling\n",
    "    df = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'])\n",
    "    df['Group'] = labels\n",
    "    df['SessionID'] = [eid for eid in all_eids]\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(df['UMAP1'], df['UMAP2'], c=df['Group'].map({'Standard': 'blue', 'Dropbox': 'red'}), label=df['Group'])\n",
    "\n",
    "    # Annotate each point with the session ID\n",
    "    for i, row in df.iterrows():\n",
    "        plt.annotate(row['SessionID'], (row['UMAP1'], row['UMAP2']), fontsize=8, alpha=0.75)\n",
    "    \n",
    "    # Create a legend with handles\n",
    "    blue_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Repro Ephys')\n",
    "    red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Dropbox')\n",
    "    \n",
    "    plt.legend(handles=[blue_patch, red_patch])\n",
    "    plt.title('UMAP Projection of Session Proportions')\n",
    "    plt.xlabel('UMAP1')\n",
    "    plt.ylabel('UMAP2')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with all the necessary parameters\n",
    "process_sessions_and_umap(eids, dropbox_eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Clustering (odd vs even trials)\n",
    "\n",
    "def calculate_time_in_state(frame_indices, states, input_fps=60):\n",
    "    time_in_state = np.zeros((len(frame_indices), 4))\n",
    "    for i, (start, end) in enumerate(frame_indices):\n",
    "        trial_states = states[start:end]\n",
    "        for state in range(4):\n",
    "            time_in_state[i, state] = np.sum(trial_states == state + 1) / input_fps # Convert frames to seconds\n",
    "    return time_in_state\n",
    "\n",
    "def get_proportions(eid, trial_indices):\n",
    "    input_fps = 60\n",
    "\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    data_gen_ibl_smooth = create_data_generator(eid, ibl_smooth_markers_file)\n",
    "    states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "    # Load trial event times\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0][trial_indices]\n",
    "    trial_end_times = trials['intervals'][:, 1][trial_indices]\n",
    "    first_movement_times = trials['firstMovement_times'][trial_indices]\n",
    "    feedback_times = trials['feedback_times'][trial_indices]\n",
    "\n",
    "    # Convert times to frame indices\n",
    "    trial_start_frame_indices = (trial_start_times * input_fps).astype(int)\n",
    "    trial_end_frame_indices = (trial_end_times * input_fps).astype(int)\n",
    "    first_movement_frame_indices = (first_movement_times * input_fps).astype(int)\n",
    "    feedback_frame_indices = (feedback_times * input_fps).astype(int)\n",
    "\n",
    "    # Calculate time in each state for both periods\n",
    "    time_in_state_first_to_feedback = calculate_time_in_state(\n",
    "        list(zip(first_movement_frame_indices, feedback_frame_indices)),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "    time_in_state_feedback_to_end = calculate_time_in_state(\n",
    "        list(zip(feedback_frame_indices, trial_end_frame_indices)),\n",
    "        states_ibl_smooth\n",
    "    )\n",
    "\n",
    "    # Define bin edges (in seconds) for histograms\n",
    "    bin_edges = [0, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 5, np.inf]\n",
    "\n",
    "    # Compute histograms\n",
    "    histograms = np.zeros((2, 4, len(bin_edges) - 1))\n",
    "    for state in range(4):\n",
    "        hist_first_to_feedback, _ = np.histogram(time_in_state_first_to_feedback[:, state], bins=bin_edges)\n",
    "        hist_feedback_to_end, _ = np.histogram(time_in_state_feedback_to_end[:, state], bins=bin_edges)\n",
    "        histograms[0, state] = hist_first_to_feedback / len(trial_start_times)\n",
    "        histograms[1, state] = hist_feedback_to_end / len(trial_start_times)\n",
    "\n",
    "    # Flatten the histograms to create the 88-dim vector\n",
    "    proportions = histograms.flatten()\n",
    "    return proportions\n",
    "\n",
    "def process_sessions_and_umap(eids, dropbox_eids):\n",
    "    input_fps = 60\n",
    "\n",
    "    # Combine the eids and dropbox_eids\n",
    "    all_eids = eids + dropbox_eids\n",
    "    \n",
    "    # Get the data for even and odd trials separately\n",
    "    even_data = []\n",
    "    odd_data = []\n",
    "    \n",
    "    for eid in all_eids:\n",
    "        trials = one.load_object(eid, 'trials')\n",
    "        num_trials = len(trials['intervals'])\n",
    "        even_trials = np.arange(0, num_trials, 2)\n",
    "        odd_trials = np.arange(1, num_trials, 2)\n",
    "        \n",
    "        even_data.append(get_proportions(eid, even_trials))\n",
    "        odd_data.append(get_proportions(eid, odd_trials))\n",
    "    \n",
    "    even_data = np.array(even_data)\n",
    "    odd_data = np.array(odd_data)\n",
    "    \n",
    "    # Concatenate the even and odd data to fit a single UMAP\n",
    "    combined_data = np.concatenate([even_data, odd_data])\n",
    "    \n",
    "    # Apply UMAP to reduce to 2D\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    embedding = reducer.fit_transform(combined_data)\n",
    "    \n",
    "    # Split the embedding into even and odd embeddings\n",
    "    embedding_even = embedding[:len(even_data)]\n",
    "    embedding_odd = embedding[len(even_data):]\n",
    "    \n",
    "    # Create DataFrames for easier handling\n",
    "    df_even = pd.DataFrame(embedding_even, columns=['UMAP1', 'UMAP2'])\n",
    "    df_even['Group'] = ['Standard'] * len(eids) + ['Dropbox'] * len(dropbox_eids)\n",
    "    df_even['SessionID'] = [eid for eid in all_eids]\n",
    "\n",
    "    df_odd = pd.DataFrame(embedding_odd, columns=['UMAP1', 'UMAP2'])\n",
    "    df_odd['Group'] = ['Standard'] * len(eids) + ['Dropbox'] * len(dropbox_eids)\n",
    "    df_odd['SessionID'] = [eid for eid in all_eids]\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter_even = plt.scatter(df_even['UMAP1'], df_even['UMAP2'], c='blue', label='Even Trials')\n",
    "    scatter_odd = plt.scatter(df_odd['UMAP1'], df_odd['UMAP2'], c='red', label='Odd Trials')\n",
    "    \n",
    "    # Connect even and odd trials with lines\n",
    "    for i in range(len(df_even)):\n",
    "        plt.plot([df_even['UMAP1'][i], df_odd['UMAP1'][i]], [df_even['UMAP2'][i], df_odd['UMAP2'][i]], 'k--', alpha=0.5)\n",
    "    \n",
    "    # Create a legend\n",
    "    plt.legend()\n",
    "    plt.title('UMAP Projection of Even and Odd Trial Proportions')\n",
    "    plt.xlabel('UMAP1')\n",
    "    plt.ylabel('UMAP2')\n",
    "    plt.show()\n",
    "\n",
    "process_sessions_and_umap(eids, dropbox_eids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 1: Trace Plots\n",
    "palette = sns.color_palette(\"tab10\", n_colors=4)\n",
    "cmap = ListedColormap(palette.as_hex())\n",
    "\n",
    "def graph_etho_img(fig, states, markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start=0, length=600):\n",
    "    n_rows = 2\n",
    "    outer_grid = gridspec.GridSpec(n_rows, 1, figure=fig, height_ratios=[.2, .8])\n",
    "    axes = [fig.add_subplot(outer_grid[i]) for i in range(n_rows)]\n",
    "\n",
    "    n_classes = np.max(states)\n",
    "\n",
    "    # Graph DAART model predictions\n",
    "    data = states[start:(start+length)]\n",
    "    graph_states(axes[0], data, n_classes)\n",
    "    axes[0].set(ylabel=\"DAART\")\n",
    "    axes[0].yaxis.label.set(rotation='horizontal', ha='right')\n",
    "\n",
    "    # Graph markers\n",
    "    markers = markers[start:(start+length)]\n",
    "    graph_markers(axes[1], markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start=start)\n",
    "\n",
    "    # Add a legend for the states\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    state_colors = sns.color_palette(\"tab10\", n_colors=4)\n",
    "    handles = [Patch(facecolor=color, edgecolor='k', label=label) for color, label in zip(state_colors, state_labels)]\n",
    "    axes[0].legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[1].set_xlabel('Time (frames)', fontsize=12)\n",
    "\n",
    "def graph_states(ax, states, n_classes):\n",
    "    n_frames = states.shape[0]\n",
    "    im = ax.imshow(\n",
    "        states[None, :], aspect='auto', \n",
    "        cmap=cmap, interpolation='none',\n",
    "        vmin=1, vmax=n_classes)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def graph_markers(ax, markers, marker_names, m_inds, trial_start_times, go_cue_times, feedback_times, start):\n",
    "    # Calculate min and max values for each marker\n",
    "    y_min = np.min(markers, axis=0)\n",
    "    y_max = np.max(markers, axis=0)\n",
    "    \n",
    "    # Define regions for each marker\n",
    "    num_markers = len(m_inds)\n",
    "    height = 1.0\n",
    "    y_offsets = np.arange(num_markers) * height\n",
    "    \n",
    "    for idx, m_idx in enumerate(m_inds):\n",
    "        marker_data = markers[:, m_idx]\n",
    "        norm_marker_data = (marker_data - y_min[m_idx]) / (y_max[m_idx] - y_min[m_idx]) * height\n",
    "        ax.plot(np.arange(len(marker_data)) + start, norm_marker_data + y_offsets[idx], color='k', linewidth=2)\n",
    "    \n",
    "    # Add vertical lines for all instances of trial start, go cue, and feedback times within the range\n",
    "    ax.vlines(trial_start_times[(trial_start_times >= start) & (trial_start_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='r', linestyle='--')\n",
    "    ax.vlines(go_cue_times[(go_cue_times >= start) & (go_cue_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='b', linestyle='--')\n",
    "    ax.vlines(feedback_times[(feedback_times >= start) & (feedback_times < start + len(markers))], ymin=-height, ymax=num_markers*height, color='g', linestyle='--')\n",
    "    \n",
    "    # Create legend handles for each event type\n",
    "    handles = [\n",
    "        Patch(color='r', linestyle='--', label='Trial Start'),\n",
    "        Patch(color='b', linestyle='--', label='Go Cue'),\n",
    "        Patch(color='g', linestyle='--', label='Feedback')\n",
    "    ]\n",
    "    \n",
    "    # Set x-axis limits and ticks\n",
    "    end = start + len(markers)\n",
    "    ax.set_xlim([start, end])\n",
    "    \n",
    "    num_ticks = 6\n",
    "    tick_positions = np.linspace(start, end, num_ticks).astype(int)\n",
    "    tick_labels = np.linspace(start, end, num_ticks).astype(int)\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    \n",
    "    ax.spines[['right', 'left']].set_visible(False)\n",
    "    ax.set_yticks(y_offsets + height / 2)\n",
    "    ax.set_yticklabels(marker_names)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "\n",
    "save_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis'\n",
    "\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "if view == 'right':\n",
    "    raise NotImplementedError\n",
    "\n",
    "for eid in eids[:1]:\n",
    "    print(f'Eid: {eid}')\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    print(f'Session: {sess_id}')\n",
    "\n",
    "    # Extract the marker data from the ibl database\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "\n",
    "    # Build the Data Generators\n",
    "    data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "\n",
    "    # Run Inference\n",
    "    states_ibl_smooth = get_states(model, data_gen_ibl_smooth)\n",
    "\n",
    "    # Ensure state values are within the correct range\n",
    "    states_ibl_smooth = np.clip(states_ibl_smooth, 1, 4)\n",
    "    \n",
    "    data_dict = {'IBL Smooth States': states_ibl_smooth}\n",
    "\n",
    "    # Load the pose data\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=0.9, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()  \n",
    "\n",
    "    # Load wheel data\n",
    "    sl.load_wheel()\n",
    "    wh_times = sl.wheel.times.to_numpy()\n",
    "    wh_vel_oversampled = sl.wheel.velocity.to_numpy()\n",
    "    \n",
    "    # Resample wheel data at marker times\n",
    "    interpolator = interp1d(wh_times, wh_vel_oversampled, fill_value='extrapolate')\n",
    "    wh_vel = interpolator(times)\n",
    "\n",
    "    # Smooth the marker data\n",
    "    markers[:, 0] = smooth_interpolate_signal_sg(markers[:, 0], window=7)\n",
    "    markers[:, 1] = smooth_interpolate_signal_sg(markers[:, 1], window=7)\n",
    "        \n",
    "    # Process the data\n",
    "    markers_comb = np.hstack([markers, wh_vel[:, None]])\n",
    "    velocity = np.vstack([np.array([0, 0, 0]), np.diff(markers_comb, axis=0)])\n",
    "    markers_comb = np.hstack([markers_comb, velocity])\n",
    "    markers_z = (markers_comb - np.mean(markers_comb, axis=0)) / np.std(markers_comb, axis=0)\n",
    "    \n",
    "    # Update marker_names and m_inds to remove paw_x_vel and wheel_acc\n",
    "    marker_names = ['paw_x_pos', 'paw_y_pos', 'wheel_vel']\n",
    "    m_inds = [0, 1, 2]\n",
    "\n",
    "    # Load trial data\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    go_cue_times = trials['goCue_times']\n",
    "    feedback_times = trials['feedback_times']\n",
    "\n",
    "    # Convert trial times to frame indices\n",
    "    frame_rate = 30  # Assuming 30 Hz frame rate, adjust this if different\n",
    "    trial_start_frames = (trial_start_times * frame_rate).astype(int)\n",
    "    go_cue_frames = (go_cue_times * frame_rate).astype(int)\n",
    "    feedback_frames = (feedback_times * frame_rate).astype(int)\n",
    "\n",
    "    # Iterate through each trial and plot\n",
    "    for trial_idx in range(len(trial_start_frames)):\n",
    "        start_frame = trial_start_frames[trial_idx]\n",
    "        if trial_idx < len(trial_start_frames) - 1:\n",
    "            end_frame = trial_start_frames[trial_idx + 1]\n",
    "        else:\n",
    "            end_frame = start_frame + 600  # Assuming a default length of 600 frames if it's the last trial\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        graph_etho_img(fig, states_ibl_smooth, markers_z, marker_names, m_inds, trial_start_frames, go_cue_frames, feedback_frames, start=start_frame, length=int(end_frame-start_frame))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace Plots Loop\n",
    "\n",
    "save_dir = '/Users/zacharyzusin/Documents/NeuroscienceResearch/repro_ephys_analysis'\n",
    "\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "if view == 'right':\n",
    "    raise NotImplementedError\n",
    "\n",
    "for eid in eids[:1]:\n",
    "    print(f'Eid: {eid}')\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    print(f'Session: {sess_id}')\n",
    "\n",
    "    # Extract the marker data from the ibl database\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "\n",
    "    # Build the Data Generators\n",
    "    data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "\n",
    "    # Run Inference\n",
    "    states_ibl_smooth = get_states(model, data_gen_ibl_smooth)\n",
    "\n",
    "    # Ensure state values are within the correct range\n",
    "    states_ibl_smooth = np.clip(states_ibl_smooth, 1, 4)\n",
    "    \n",
    "    data_dict = {'IBL Smooth States': states_ibl_smooth}\n",
    "\n",
    "    # Load the pose data\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=0.9, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()  \n",
    "\n",
    "    # Load wheel data\n",
    "    sl.load_wheel()\n",
    "    wh_times = sl.wheel.times.to_numpy()\n",
    "    wh_vel_oversampled = sl.wheel.velocity.to_numpy()\n",
    "    \n",
    "    # Resample wheel data at marker times\n",
    "    interpolator = interp1d(wh_times, wh_vel_oversampled, fill_value='extrapolate')\n",
    "    wh_vel = interpolator(times)\n",
    "\n",
    "    # Smooth the marker data\n",
    "    markers[:, 0] = smooth_interpolate_signal_sg(markers[:, 0], window=7)\n",
    "    markers[:, 1] = smooth_interpolate_signal_sg(markers[:, 1], window=7)\n",
    "        \n",
    "    # Process the data\n",
    "    markers_comb = np.hstack([markers, wh_vel[:, None]])\n",
    "    velocity = np.vstack([np.array([0, 0, 0]), np.diff(markers_comb, axis=0)])\n",
    "    markers_comb = np.hstack([markers_comb, velocity])\n",
    "    markers_z = (markers_comb - np.mean(markers_comb, axis=0)) / np.std(markers_comb, axis=0)\n",
    "    \n",
    "    # Update marker_names and m_inds to remove paw_x_vel and wheel_acc\n",
    "    marker_names = ['paw_x_pos', 'paw_y_pos', 'wheel_vel']\n",
    "    m_inds = [0, 1, 2]\n",
    "\n",
    "    # Load trial data\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    go_cue_times = trials['goCue_times']\n",
    "    feedback_times = trials['feedback_times']\n",
    "\n",
    "    # Convert trial times to frame indices\n",
    "    frame_rate = 30  # Assuming 30 Hz frame rate, adjust this if different\n",
    "    trial_start_frames = (trial_start_times * frame_rate).astype(int)\n",
    "    go_cue_frames = (go_cue_times * frame_rate).astype(int)\n",
    "    feedback_frames = (feedback_times * frame_rate).astype(int)\n",
    "\n",
    "    # Iterate through each trial and plot\n",
    "    for trial_idx in range(len(trial_start_frames)):\n",
    "        start_frame = trial_start_frames[trial_idx]\n",
    "        if trial_idx < len(trial_start_frames) - 1:\n",
    "            end_frame = trial_start_frames[trial_idx + 1]\n",
    "        else:\n",
    "            end_frame = start_frame + 600  # Assuming a default length of 600 frames if it's the last trial\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        graph_etho_img(fig, states_ibl_smooth, markers_z, marker_names, m_inds, trial_start_frames, go_cue_frames, feedback_frames, start=start_frame, length=int(end_frame-start_frame))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 2: Per State Scatterplots of Paw Locations\n",
    "\n",
    "# Function to overlay paw locations on a video frame\n",
    "def overlay_paw_locations_on_frame(frame, paw_coordinates, color):\n",
    "    for (x, y) in paw_coordinates:\n",
    "        if not np.isnan(x) and not np.isnan(y):\n",
    "            cv2.circle(frame, (int(x), int(y)), 3, color, -1)\n",
    "\n",
    "# Function to scatter paw locations on video frames for each state\n",
    "def scatter_paw_locations_on_video_frame(states, markers, video_path):\n",
    "    colors = {\n",
    "        'Still': (255, 0, 0),       # Blue\n",
    "        'Move': (0, 165, 255),      # Orange\n",
    "        'Wheel Turn': (0, 255, 0),  # Green\n",
    "        'Groom': (0, 0, 255)        # Red\n",
    "    }\n",
    "    state_to_label = {1: 'Still', 2: 'Move', 3: 'Wheel Turn', 4: 'Groom'}\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_frame_number = random.randint(0, total_frames - 1)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read the frame from video\")\n",
    "        return\n",
    "\n",
    "    unique_states = np.unique(states)\n",
    "    fig, axes = plt.subplots(1, len(unique_states), figsize=(20, 5))\n",
    "    for i, state in enumerate(unique_states):\n",
    "        state_indices = np.where(states == state)\n",
    "        paw_coordinates = markers[state_indices]\n",
    "\n",
    "        overlay_frame = frame.copy()\n",
    "        label = state_to_label[state]\n",
    "        overlay_paw_locations_on_frame(overlay_frame, paw_coordinates, colors[label])\n",
    "\n",
    "        axes[i].imshow(cv2.cvtColor(overlay_frame, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(f'{label} Paw Locations')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 3: Wheel Position Conditioned on State Transition\n",
    "\n",
    "def plot_relative_wheel_position_conditioned_on_frequent_transitions(eid, wh_times, wh_pos, states, times, trials, pre_window=(-0.25, 0), post_window=(0, 1.5), transition_threshold=5, sampling_rate=60):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = sns.color_palette(\"tab10\", n_colors=4)\n",
    "\n",
    "    # Resample wheel data at trial times\n",
    "    interpolator = interp1d(wh_times, wh_pos, fill_value='extrapolate')\n",
    "    wh_pos_resampled = interpolator(times)\n",
    "\n",
    "    # Load stimulus onset times\n",
    "    stimOn_times = trials['stimOn_times']\n",
    "    choices = trials['choice']\n",
    "\n",
    "    # Ensure states and times arrays have the same length\n",
    "    min_length = min(len(times), len(states))\n",
    "    times = times[:min_length]\n",
    "    states = states[:min_length]\n",
    "\n",
    "    # Define the windows\n",
    "    num_pre_frames = int((pre_window[1] - pre_window[0]) * sampling_rate)\n",
    "    num_post_frames = int((post_window[1] - post_window[0]) * sampling_rate)\n",
    "\n",
    "    # Initialize plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Identify transitions\n",
    "    transitions = []\n",
    "\n",
    "    for i, onset in enumerate(stimOn_times):\n",
    "        if choices[i] == 0:  # Skip trials with no turn\n",
    "            continue\n",
    "\n",
    "        pre_mask = (times >= (onset + pre_window[0])) & (times <= (onset + pre_window[1]))\n",
    "        post_mask = (times >= (onset + post_window[0])) & (times <= (onset + post_window[1]))\n",
    "\n",
    "        if np.sum(pre_mask) == 0 or np.sum(post_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pre_states = states[pre_mask]\n",
    "        post_states = states[post_mask]\n",
    "\n",
    "        if len(pre_states) == 0 or len(post_states) == 0:\n",
    "            continue\n",
    "\n",
    "        most_common_pre_state = Counter(pre_states).most_common(1)[0][0]\n",
    "        most_common_post_state = Counter(post_states).most_common(1)[0][0]\n",
    "\n",
    "        # Check if the pre-state and post-state are different\n",
    "        if most_common_pre_state != most_common_post_state:\n",
    "            transitions.append((most_common_pre_state, most_common_post_state, choices[i]))\n",
    "\n",
    "    # Count transitions\n",
    "    transition_counts = Counter((pre, post, choice) for pre, post, choice in transitions)\n",
    "\n",
    "    # Filter transitions that occur frequently enough\n",
    "    frequent_transitions = [(pre, post) for (pre, post, choice), count in transition_counts.items() if count >= transition_threshold]\n",
    "\n",
    "    max_abs_val = 0\n",
    "\n",
    "    for transition in frequent_transitions:\n",
    "        pre_state, post_state = transition\n",
    "        transition_times = []\n",
    "\n",
    "        for i, onset in enumerate(stimOn_times):\n",
    "            if choices[i] == 0:  # Skip trials with no turn\n",
    "                continue\n",
    "\n",
    "            pre_mask = (times >= (onset + pre_window[0])) & (times <= (onset + pre_window[1]))\n",
    "            post_mask = (times >= (onset + post_window[0])) & (times <= (onset + post_window[1]))\n",
    "\n",
    "            if np.sum(pre_mask) == 0 or np.sum(post_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            pre_states = states[pre_mask]\n",
    "            post_states = states[post_mask]\n",
    "\n",
    "            if len(pre_states) == 0 or len(post_states) == 0:\n",
    "                continue\n",
    "\n",
    "            most_common_pre_state = Counter(pre_states).most_common(1)[0][0]\n",
    "            most_common_post_state = Counter(post_states).most_common(1)[0][0]\n",
    "\n",
    "            # Check if the pre-state and post-state are different\n",
    "            if most_common_pre_state != most_common_post_state:\n",
    "                if most_common_pre_state == pre_state and most_common_post_state == post_state:\n",
    "                    transition_times.append((onset, choices[i]))  # Store onset and associated choice\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        for onset, choice in transition_times:\n",
    "            mask = (times >= (onset + pre_window[0])) & (times <= (onset + post_window[1]))\n",
    "            if np.sum(mask) == 0:\n",
    "                continue\n",
    "\n",
    "            onset_times = times[mask] - onset\n",
    "            onset_wheel_pos = wh_pos_resampled[mask]\n",
    "            onset_states = states[mask]\n",
    "\n",
    "            # Interpolate to have a consistent number of frames\n",
    "            interp_times = np.linspace(pre_window[0], post_window[1], num_pre_frames + num_post_frames)\n",
    "            interp_wheel_pos = np.interp(interp_times, onset_times, onset_wheel_pos)\n",
    "            interp_states = np.interp(interp_times, onset_times, onset_states, left=-1, right=-1)\n",
    "\n",
    "            # Adjust to relative wheel position\n",
    "            relative_wheel_pos = interp_wheel_pos - interp_wheel_pos[0]\n",
    "\n",
    "            # Update the maximum absolute value for y-axis limits\n",
    "            max_abs_val = max(max_abs_val, np.max(np.abs(relative_wheel_pos)))\n",
    "\n",
    "            # Determine the color based on the choice\n",
    "            color = 'red' if choice == 1 else 'blue'  # Right turn is red, left turn is blue\n",
    "\n",
    "            # Plot each trial's relative wheel position\n",
    "            plt.plot(interp_times, relative_wheel_pos, alpha=0.5, color=color)\n",
    "\n",
    "        # Plot the state bar at the bottom\n",
    "        state_colors = np.array([cmap[int(s)-1] if s != -1 else (1, 1, 1) for s in interp_states])  # Use white for undefined states\n",
    "        plt.imshow([state_colors], aspect='auto', extent=[pre_window[0], post_window[1], -max_abs_val, -max_abs_val - 0.1], interpolation='nearest')\n",
    "\n",
    "        # Set symmetrical y-axis limits\n",
    "        plt.ylim(-max_abs_val - 0.1, max_abs_val)\n",
    "\n",
    "        # Add a vertical line at stimulus onset time\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Relative Wheel Position (radians)')\n",
    "        plt.title(f'Relative Wheel Position Over Time Conditioned on Transition {state_labels[pre_state-1]} to {state_labels[post_state-1]} for Session: {sess_id}')\n",
    "\n",
    "        # Add legend\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='red', lw=2, label='Right Turn'),\n",
    "            Line2D([0], [0], color='blue', lw=2, label='Left Turn'),\n",
    "            Line2D([0], [0], color='k', lw=2, linestyle='--', label='Stimulus Onset'),\n",
    "            Line2D([0], [0], color=cmap[0], lw=2, label='Still'),\n",
    "            Line2D([0], [0], color=cmap[1], lw=2, label='Move'),\n",
    "            Line2D([0], [0], color=cmap[2], lw=2, label='Wheel Turn'),\n",
    "            Line2D([0], [0], color=cmap[3], lw=2, label='Groom')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 4: Paw Speed Conditioned on State Transition\n",
    "\n",
    "def plot_relative_paw_speed_conditioned_on_state_transitions(eid, times, paw_x_vel, paw_y_vel, states, trials, pre_window=(-0.5, 0), post_window=(0, 1.5), transition_threshold=5, sampling_rate=60):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "\n",
    "    paw_speed = np.sqrt(paw_x_vel ** 2 + paw_y_vel ** 2)\n",
    "\n",
    "    stimOn_times = trials['stimOn_times']\n",
    "    choices = trials['choice']\n",
    "    feedbackTypes = trials['feedbackType']\n",
    "\n",
    "    min_length = min(len(times), len(states))\n",
    "    times = times[:min_length]\n",
    "    states = states[:min_length]\n",
    "\n",
    "    num_pre_frames = int((pre_window[1] - pre_window[0]) * sampling_rate)\n",
    "    num_post_frames = int((post_window[1] - post_window[0]) * sampling_rate)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i, onset in enumerate(stimOn_times):\n",
    "        if choices[i] == 0:\n",
    "            continue\n",
    "\n",
    "        pre_mask = (times >= (onset + pre_window[0])) & (times <= (onset + pre_window[1]))\n",
    "        post_mask = (times >= (onset + post_window[0])) & (times <= (onset + post_window[1]))\n",
    "\n",
    "        if np.sum(pre_mask) == 0 or np.sum(post_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        pre_states = states[pre_mask]\n",
    "        post_states = states[post_mask]\n",
    "\n",
    "        if len(pre_states) == 0 or len(post_states) == 0:\n",
    "            continue\n",
    "\n",
    "        most_common_pre_state = Counter(pre_states).most_common(1)[0][0]\n",
    "        most_common_post_state = Counter(post_states).most_common(1)[0][0]\n",
    "\n",
    "        if most_common_pre_state != most_common_post_state:\n",
    "            transitions.append((most_common_pre_state, most_common_post_state, choices[i], feedbackTypes[i]))\n",
    "\n",
    "    transition_counts = Counter((pre, post, choice) for pre, post, choice, feedback in transitions)\n",
    "\n",
    "    frequent_transitions = [(pre, post) for (pre, post, choice), count in transition_counts.items() if count >= transition_threshold]\n",
    "\n",
    "    max_abs_val = 0\n",
    "\n",
    "    for transition in frequent_transitions:\n",
    "        pre_state, post_state = transition\n",
    "        transition_times = []\n",
    "\n",
    "        for i, onset in enumerate(stimOn_times):\n",
    "            if choices[i] == 0:\n",
    "                continue\n",
    "\n",
    "            pre_mask = (times >= (onset + pre_window[0])) & (times <= (onset + pre_window[1]))\n",
    "            post_mask = (times >= (onset + post_window[0])) & (times <= (onset + post_window[1]))\n",
    "\n",
    "            if np.sum(pre_mask) == 0 or np.sum(post_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            pre_states = states[pre_mask]\n",
    "            post_states = states[post_mask]\n",
    "\n",
    "            if len(pre_states) == 0 or len(post_states) == 0:\n",
    "                continue\n",
    "\n",
    "            most_common_pre_state = Counter(pre_states).most_common(1)[0][0]\n",
    "            most_common_post_state = Counter(post_states).most_common(1)[0][0]\n",
    "\n",
    "            if most_common_pre_state != most_common_post_state:\n",
    "                if most_common_pre_state == pre_state and most_common_post_state == post_state:\n",
    "                    transition_times.append((onset, choices[i], feedbackTypes[i]))\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        for onset, choice, feedback in transition_times:\n",
    "            mask = (times >= (onset + pre_window[0])) & (times <= (onset + post_window[1]))\n",
    "            if np.sum(mask) == 0:\n",
    "                continue\n",
    "\n",
    "            onset_times = times[mask] - onset\n",
    "            onset_paw_speed = paw_speed[mask]\n",
    "\n",
    "            interp_times = np.linspace(pre_window[0], post_window[1], num_pre_frames + num_post_frames)\n",
    "            interp_paw_speed = np.interp(interp_times, onset_times, onset_paw_speed)\n",
    "\n",
    "            max_abs_val = max(max_abs_val, np.max(interp_paw_speed))\n",
    "\n",
    "            color_paw = 'black' if feedback == 1 else 'grey'\n",
    "\n",
    "            plt.plot(interp_times, interp_paw_speed, alpha=0.5, color=color_paw)\n",
    "\n",
    "        plt.ylim(0, max_abs_val)\n",
    "\n",
    "        plt.axvline(x=0, color='red', linestyle='--')\n",
    "\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Paw Speed')\n",
    "        plt.title(f'Paw Speed Over Time Conditioned on Transition {state_labels[pre_state-1]} to {state_labels[post_state-1]} for Session: {sess_id}')\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='black', lw=2, label='Correct Trial'),\n",
    "            Line2D([0], [0], color='#D3D3D3', lw=2, label='Incorrect Trial'),\n",
    "            Line2D([0], [0], color='red', lw=2, linestyle='--', label='Stimulus Onset')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics Loop\n",
    "\n",
    "for eid in eids[:1]:\n",
    "    print(f'Eid: {eid}')\n",
    "    \n",
    "    #Session Loader Parameters\n",
    "    l_thresh_smooth = 0.9\n",
    "    view = 'left'\n",
    "    paw = 'paw_r'\n",
    "    \n",
    "    # Load trial times\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()\n",
    "\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "\n",
    "    # Load wheel data\n",
    "    sl.load_wheel()\n",
    "    wh_times = sl.wheel.times.to_numpy()\n",
    "    wh_pos = sl.wheel.position.to_numpy()\n",
    "\n",
    "    # Generate state predictions\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "    states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "    # Provide the path to the session's video\n",
    "    video_path = vidio.url_from_eid(eid, one=one)[view]\n",
    "    \n",
    "    scatter_paw_locations_on_video_frame(states_ibl_smooth, markers, video_path)\n",
    "    plot_relative_wheel_position_conditioned_on_frequent_transitions(eid, wh_times, wh_pos, states_ibl_smooth, times[:len(states_ibl_smooth)], trials)\n",
    "\n",
    "    # Load marker data for paw velocities\n",
    "    file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    df = pd.read_csv(file)\n",
    "    paw_x_vel = df['paw_x_vel'].to_numpy()\n",
    "    paw_y_vel = df['paw_y_vel'].to_numpy()\n",
    "    plot_relative_paw_speed_conditioned_on_state_transitions(eid, times[:len(states_ibl_smooth)], paw_x_vel[:len(states_ibl_smooth)], paw_y_vel[:len(states_ibl_smooth)], states_ibl_smooth, trials)\n",
    "    create_states_aligned_heatmap(eid, l_thresh_smooth, view, paw, align_event='stimOn_times', split_by_feedback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (INCOMPLETE)\n",
    "\n",
    "def extract_state_runs(states, min_length=20, transition_threshold=20):\n",
    "        \n",
    "        K = int(np.max(states) + 1)\n",
    "        state_snippets = [[] for _ in range(K)]\n",
    "        transitions = []\n",
    "\n",
    "        buffer = 100\n",
    "\n",
    "        i_beg = buffer\n",
    "        curr_state = states[i_beg]\n",
    "        curr_len = 1\n",
    "\n",
    "        for i in range(i_beg + 1, len(states) - buffer):\n",
    "            next_state = states[i]\n",
    "            if next_state != curr_state:\n",
    "                # Record indices if state duration long enough\n",
    "                if curr_len >= min_length:\n",
    "                    state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "\n",
    "                # Check for nearby different state chunks\n",
    "                if len(state_snippets[next_state]) > 0:\n",
    "                    for prev_chunk in state_snippets[curr_state]:\n",
    "                        if np.abs(prev_chunk[-1] - i_beg) <= transition_threshold:\n",
    "                            transition_frame = (prev_chunk[-1] + i_beg) // 2\n",
    "                            transitions.append((transition_frame, curr_state, next_state))\n",
    "                            break\n",
    "                \n",
    "                i_beg = i\n",
    "                curr_state = next_state\n",
    "                curr_len = 1\n",
    "            else:\n",
    "                curr_len += 1\n",
    "        \n",
    "        # End of trial cleanup\n",
    "        if curr_len >= min_length:\n",
    "            state_snippets[curr_state].append(np.arange(i_beg, len(states) - buffer))\n",
    "\n",
    "        return {\n",
    "            \"state_snippets\": state_snippets,\n",
    "            \"transitions\": transitions\n",
    "        }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "def plot_wheel_around_state_transitions(one, eid, model, sess_id, min_length=20, transition_threshold=20, window_size=100):\n",
    "\n",
    "    # Session Loader Parameters\n",
    "    l_thresh_smooth = 0.9\n",
    "    view = 'left'\n",
    "    paw = 'paw_r'\n",
    "\n",
    "    # Load trial times\n",
    "    sl = SessionLoader(one=one, eid=eid)\n",
    "    sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "    times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "    markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()\n",
    "\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "\n",
    "    # Load wheel data\n",
    "    sl.load_wheel()\n",
    "    wh_times = sl.wheel.times.to_numpy()\n",
    "    wh_pos = sl.wheel.position.to_numpy()\n",
    "\n",
    "    # Generate state predictions\n",
    "    ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "    data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "    states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "    # Identify state transitions\n",
    "    state_info = extract_state_runs(states_ibl_smooth, min_length, transition_threshold)\n",
    "    transitions = state_info[\"transitions\"]\n",
    "\n",
    "    # Convert wheel times to frames\n",
    "    wh_times_frames = np.interp(times, wh_times, np.arange(len(wh_times)))[:-4]\n",
    "\n",
    "    # Plot wheel position around state transitions\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for transition_frame, curr_state, next_state in transitions:\n",
    "        start_frame = max(0, transition_frame - window_size // 2)\n",
    "        end_frame = min(len(states_ibl_smooth), transition_frame + window_size // 2)\n",
    "        window_frames = np.arange(start_frame, end_frame)\n",
    "\n",
    "        wheel_window = np.interp(window_frames, wh_times_frames, wh_pos)\n",
    "        \n",
    "        ax.plot(window_frames - transition_frame, wheel_window, label=f'Transition {curr_state}->{next_state}')\n",
    "\n",
    "    ax.axvline(x=0, color='r', linestyle='--')\n",
    "    ax.set_xlabel('Frames around transition')\n",
    "    \n",
    "    ax.set_ylabel('Wheel position')\n",
    "    ax.legend()\n",
    "    ax.set_title('Wheel Position Around State Transitions')\n",
    "    plt.show()\n",
    "\n",
    "plot_wheel_around_state_transitions(one, eid, model, sess_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (INCOMPLETE)\n",
    "\n",
    "def extract_state_runs(states, min_length=20):\n",
    "    K = int(np.max(states) + 1)\n",
    "    state_snippets = [[] for _ in range(K)]\n",
    "    end_indices = [[] for _ in range(K)]\n",
    "\n",
    "    buffer = 100\n",
    "    \n",
    "    i_beg = buffer\n",
    "    curr_state = states[i_beg]\n",
    "    curr_len = 1\n",
    "    for i in range(i_beg + 1, len(states) - buffer):\n",
    "        next_state = states[i]\n",
    "        if next_state != curr_state:\n",
    "            # record indices if state duration long enough\n",
    "            if curr_len >= min_length:\n",
    "                state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "                end_indices[curr_state].append(i - 1)  # Store end index of the chunk\n",
    "            i_beg = i\n",
    "            curr_state = next_state\n",
    "            curr_len = 1\n",
    "        else:\n",
    "            curr_len += 1\n",
    "    # end of trial cleanup\n",
    "    if curr_len >= min_length:\n",
    "        state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "        end_indices[curr_state].append(i - 1)\n",
    "    return state_snippets, end_indices\n",
    "\n",
    "def plot_absolute_wheel_position_conditioned_on_frequent_transitions(eid, wh_times, wh_pos, states, times, pre_window=(-0.25, 0), post_window=(0, 1.5), transition_threshold=5, sampling_rate=60, min_chunk_length=20, max_frame_distance=30):\n",
    "    sess_id = dropbox_marker_paths[eid]\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = sns.color_palette(\"tab10\", n_colors=4)\n",
    "\n",
    "    # Resample wheel data at trial times\n",
    "    interpolator = interp1d(wh_times, wh_pos, fill_value='extrapolate')\n",
    "    wh_pos_resampled = interpolator(times)\n",
    "\n",
    "    # Define the windows\n",
    "    num_pre_frames = int((pre_window[1] - pre_window[0]) * sampling_rate)\n",
    "    num_post_frames = int((post_window[1] - post_window[0]) * sampling_rate)\n",
    "\n",
    "    # Extract state runs\n",
    "    state_snippets, end_indices = extract_state_runs(states, min_length=min_chunk_length)\n",
    "\n",
    "    # Identify transitions between contiguous chunks of different states within the frame distance\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(state_snippets)):\n",
    "        for chunk, end_idx in zip(state_snippets[i], end_indices[i]):\n",
    "            # Look for chunks in other states that start within the max_frame_distance\n",
    "            for j in range(len(state_snippets)):\n",
    "                if i != j:  # Ensure different states\n",
    "                    for next_chunk in state_snippets[j]:\n",
    "                        start_idx = next_chunk[0]\n",
    "                        if 0 < start_idx - end_idx <= max_frame_distance:\n",
    "                            transitions.append((i, j, chunk, next_chunk, times[start_idx]))\n",
    "\n",
    "    # Count transitions\n",
    "    transition_counts = Counter((pre, post) for pre, post, _, _, _ in transitions)\n",
    "    \n",
    "    # Filter transitions that occur frequently enough\n",
    "    frequent_transitions = [(pre, post) for (pre, post), count in transition_counts.items() if count >= transition_threshold]\n",
    "\n",
    "    max_abs_val = 0\n",
    "\n",
    "    for transition in frequent_transitions:\n",
    "        pre_state, post_state = transition\n",
    "        transition_times = [time for pre, post, _, _, time in transitions if pre == pre_state and post == post_state]\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        for onset in transition_times:\n",
    "            mask = (times >= (onset + pre_window[0])) & (times <= (onset + post_window[1]))\n",
    "            if np.sum(mask) == 0:\n",
    "                continue\n",
    "\n",
    "            onset_times = times[mask] - onset\n",
    "            onset_wheel_pos = wh_pos_resampled[mask]\n",
    "            onset_states = states[mask]\n",
    "\n",
    "            # Interpolate to have a consistent number of frames\n",
    "            interp_times = np.linspace(pre_window[0], post_window[1], num_pre_frames + num_post_frames)\n",
    "            interp_wheel_pos = np.interp(interp_times, onset_times, onset_wheel_pos)\n",
    "            interp_states = np.interp(interp_times, onset_times, onset_states, left=-1, right=-1)\n",
    "\n",
    "            # Update the maximum absolute value for y-axis limits\n",
    "            max_abs_val = max(max_abs_val, np.max(np.abs(interp_wheel_pos)))\n",
    "\n",
    "            # Determine the color based on the state transition\n",
    "            color = cmap[pre_state]\n",
    "\n",
    "            # Plot each trial's absolute wheel position\n",
    "            plt.plot(interp_times, interp_wheel_pos, alpha=0.5, color=color)\n",
    "\n",
    "        # Set symmetrical y-axis limits\n",
    "        plt.ylim(-max_abs_val - 0.1, max_abs_val)\n",
    "\n",
    "        # Add a vertical line at transition time\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Absolute Wheel Position (radians)')\n",
    "        plt.title(f'Absolute Wheel Position Over Time Conditioned on Transition {state_labels[pre_state]} to {state_labels[post_state]} for Session: {sess_id}')\n",
    "\n",
    "        # Add legend\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='k', lw=2, linestyle='--', label='State Transition'),\n",
    "            Line2D([0], [0], color=cmap[0], lw=2, label='Still'),\n",
    "            Line2D([0], [0], color=cmap[1], lw=2, label='Move'),\n",
    "            Line2D([0], [0], color=cmap[2], lw=2, label='Wheel Turn'),\n",
    "            Line2D([0], [0], color=cmap[3], lw=2, label='Groom')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "# Session Loader Parameters\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "# Load trial times\n",
    "sl = SessionLoader(one=one, eid=eid)\n",
    "sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()\n",
    "\n",
    "trials = one.load_object(eid, 'trials')\n",
    "\n",
    "# Load wheel data\n",
    "sl.load_wheel()\n",
    "wh_times = sl.wheel.times.to_numpy()\n",
    "wh_pos = sl.wheel.position.to_numpy()\n",
    "\n",
    "# Generate state predictions\n",
    "ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "# Convert wheel times to frames\n",
    "wh_times_frames = np.interp(times, wh_times, np.arange(len(wh_times)))[:-4]\n",
    "plot_absolute_wheel_position_conditioned_on_frequent_transitions(eid, wh_times, wh_pos, states_ibl_smooth, times[:len(states_ibl_smooth)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (INCOMPLETE)\n",
    "\n",
    "def extract_state_runs(states, min_length=20):\n",
    "    K = int(np.max(states) + 1)\n",
    "    state_snippets = [[] for _ in range(K)]\n",
    "\n",
    "    buffer = 100\n",
    "    \n",
    "    i_beg = buffer\n",
    "    curr_state = states[i_beg]\n",
    "    curr_len = 1\n",
    "    for i in range(i_beg + 1, len(states) - buffer):\n",
    "        next_state = states[i]\n",
    "        if next_state != curr_state:\n",
    "            if curr_len >= min_length:\n",
    "                state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "            i_beg = i\n",
    "            curr_state = next_state\n",
    "            curr_len = 1\n",
    "        else:\n",
    "            curr_len += 1\n",
    "    if curr_len >= min_length:\n",
    "        state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "    return state_snippets\n",
    "\n",
    "def plot_relative_wheel_positions_around_transitions(eid, wh_times, wh_pos, states, times, pre_window=(-0.25, 0), post_window=(0, 1.5), max_frame_distance=30):\n",
    "    \n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "    interpolator = interp1d(wh_times, wh_pos, fill_value='extrapolate')\n",
    "    wh_pos_resampled = interpolator(times)\n",
    "\n",
    "    state_snippets = extract_state_runs(states, min_length=20)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(state_snippets)):\n",
    "        for chunk in state_snippets[i]:\n",
    "            end_idx = chunk[-1]\n",
    "            for j in range(len(state_snippets)):\n",
    "                if i != j:  \n",
    "                    for next_chunk in state_snippets[j]:\n",
    "                        start_idx = next_chunk[0]\n",
    "                        if 0 < start_idx - end_idx <= max_frame_distance:\n",
    "                            transitions.append((i, j, chunk, next_chunk, times[start_idx]))\n",
    "\n",
    "    transition_groups = defaultdict(list)\n",
    "    for pre_state, post_state, _, _, _ in transitions:\n",
    "        transition_groups[(pre_state, post_state)].append(_)\n",
    "\n",
    "    for (pre_state, post_state), transition_times in transition_groups.items():\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        legend_added = {'pre': False, 'post': False}\n",
    "        \n",
    "        for transition_time in transition_times:\n",
    "            pre_mask = (times >= (transition_time + pre_window[0])) & (times <= (transition_time + pre_window[1]))\n",
    "            if np.sum(pre_mask) > 0:\n",
    "                pre_times = times[pre_mask] - transition_time\n",
    "                pre_wheel_pos = wh_pos_resampled[pre_mask]\n",
    "                relative_pre_wheel_pos = pre_wheel_pos - pre_wheel_pos[0]\n",
    "                plt.plot(pre_times, relative_pre_wheel_pos, alpha=0.5, color=cmap(pre_state), linestyle='--' if not legend_added['pre'] else '', label=f'{state_labels[pre_state]} (Pre-Transition)')\n",
    "                legend_added['pre'] = True\n",
    "            \n",
    "            post_mask = (times >= (transition_time + post_window[0])) & (times <= (transition_time + post_window[1]))\n",
    "            if np.sum(post_mask) > 0:\n",
    "                post_times = times[post_mask] - transition_time\n",
    "                post_wheel_pos = wh_pos_resampled[post_mask]\n",
    "                relative_post_wheel_pos = post_wheel_pos - post_wheel_pos[0]\n",
    "                plt.plot(post_times, relative_post_wheel_pos, alpha=0.5, color=cmap(post_state), linestyle='-' if not legend_added['post'] else '', label=f'{state_labels[post_state]} (Post-Transition)')\n",
    "                legend_added['post'] = True\n",
    "\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Relative Wheel Position (radians)')\n",
    "        plt.title(f'Relative Wheel Position Around Transition {state_labels[pre_state]} to {state_labels[post_state]}')\n",
    "        \n",
    "        plt.legend(loc='best')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "sl = SessionLoader(one=one, eid=eid)\n",
    "sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()\n",
    "\n",
    "trials = one.load_object(eid, 'trials')\n",
    "\n",
    "sl.load_wheel()\n",
    "wh_times = sl.wheel.times.to_numpy()\n",
    "wh_pos = sl.wheel.position.to_numpy()\n",
    "\n",
    "ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "wh_times_frames = np.interp(times, wh_times, np.arange(len(wh_times)))[:-4]\n",
    "\n",
    "plot_relative_wheel_positions_around_transitions(eids[0], wh_times, wh_pos, states_ibl_smooth, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (INCOMPLETE)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_state_runs(states, min_length=20):\n",
    "    K = int(np.max(states) + 1)\n",
    "    state_snippets = [[] for _ in range(K)]\n",
    "\n",
    "    buffer = 100\n",
    "    \n",
    "    i_beg = buffer\n",
    "    curr_state = states[i_beg]\n",
    "    curr_len = 1\n",
    "    for i in range(i_beg + 1, len(states) - buffer):\n",
    "        next_state = states[i]\n",
    "        if next_state != curr_state:\n",
    "            if curr_len >= min_length:\n",
    "                state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "            i_beg = i\n",
    "            curr_state = next_state\n",
    "            curr_len = 1\n",
    "        else:\n",
    "            curr_len += 1\n",
    "\n",
    "    if curr_len >= min_length:\n",
    "        state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "    return state_snippets\n",
    "\n",
    "def plot_relative_wheel_positions_around_transitions(eid, wh_times, wh_pos, states, times, pre_window=(-0.25, 0), post_window=(0, 1.5), max_frame_distance=30):\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "    interpolator = interp1d(wh_times, wh_pos, fill_value='extrapolate')\n",
    "    wh_pos_resampled = interpolator(times)\n",
    "\n",
    "    state_snippets = extract_state_runs(states, min_length=20)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(state_snippets)):\n",
    "        for chunk in state_snippets[i]:\n",
    "            end_idx = chunk[-1]\n",
    "            for j in range(len(state_snippets)):\n",
    "                if i != j:\n",
    "                    for next_chunk in state_snippets[j]:\n",
    "                        start_idx = next_chunk[0]\n",
    "                        if 0 < start_idx - end_idx <= max_frame_distance:\n",
    "                            transitions.append((i, j, chunk, next_chunk, times[start_idx]))\n",
    "\n",
    "    # Filter transitions for Still to Move/Wheel Turn and Move/Wheel Turn to Still\n",
    "    filtered_transitions = [\n",
    "        (pre_state, post_state, chunk, next_chunk, transition_time)\n",
    "        for pre_state, post_state, chunk, next_chunk, transition_time in transitions\n",
    "        if (pre_state == 1 and post_state in [2, 3]) or (pre_state in [2, 3] and post_state == 1)\n",
    "    ]\n",
    "\n",
    "    # Group transitions by (pre_state, post_state)\n",
    "    transition_groups = defaultdict(list)\n",
    "    for pre_state, post_state, _, _, transition_time in filtered_transitions:\n",
    "        transition_groups[(pre_state, post_state)].append(transition_time)\n",
    "\n",
    "    # Plot wheel positions for each transition group\n",
    "    for (pre_state, post_state), transition_times in transition_groups.items():\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        # Plot all transitions for this state pair\n",
    "        for transition_time in transition_times:\n",
    "            pre_mask = (times >= (transition_time + pre_window[0])) & (times <= (transition_time + pre_window[1]))\n",
    "            if np.sum(pre_mask) > 0:\n",
    "                pre_times = times[pre_mask] - transition_time\n",
    "                pre_wheel_pos = wh_pos_resampled[pre_mask]\n",
    "                relative_pre_wheel_pos = pre_wheel_pos - pre_wheel_pos[0]\n",
    "                plt.plot(pre_times, relative_pre_wheel_pos, alpha=0.5, color=cmap(pre_state-1))\n",
    "\n",
    "            # Plot post-transition chunk\n",
    "            post_mask = (times >= (transition_time + post_window[0])) & (times <= (transition_time + post_window[1]))\n",
    "            if np.sum(post_mask) > 0:\n",
    "                post_times = times[post_mask] - transition_time\n",
    "                post_wheel_pos = wh_pos_resampled[post_mask]\n",
    "                relative_post_wheel_pos = post_wheel_pos - pre_wheel_pos[0]\n",
    "                plt.plot(post_times, relative_post_wheel_pos, alpha=0.5, color=cmap(post_state-1))\n",
    "\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Relative Wheel Position (radians)')\n",
    "        plt.title(f'Relative Wheel Position Around Transition {state_labels[pre_state-1]} to {state_labels[post_state-1]}')\n",
    "\n",
    "        plt.legend([\n",
    "            f'{state_labels[pre_state-1]} (Pre-Transition)',\n",
    "            f'{state_labels[post_state-1]} (Post-Transition)'\n",
    "        ], loc='best')\n",
    "        plt.show()\n",
    "\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "sl = SessionLoader(one=one, eid=eid)\n",
    "sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "markers = sl.pose[f'{view}Camera'].loc[:, (f'{paw}_x', f'{paw}_y')].to_numpy()\n",
    "\n",
    "trials = one.load_object(eid, 'trials')\n",
    "\n",
    "sl.load_wheel()\n",
    "wh_times = sl.wheel.times.to_numpy()\n",
    "wh_pos = sl.wheel.position.to_numpy()\n",
    "\n",
    "ibl_smooth_markers_file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "data_gen_ibl_smooth = create_data_generator(sess_id, ibl_smooth_markers_file)\n",
    "states_ibl_smooth = np.clip(get_states(model, data_gen_ibl_smooth), 1, 4)\n",
    "\n",
    "wh_times_frames = np.interp(times, wh_times, np.arange(len(wh_times)))[:-4]\n",
    "\n",
    "sl.load_wheel()\n",
    "wh_times = sl.wheel.times.to_numpy()\n",
    "wh_vel_oversampled = sl.wheel.velocity.to_numpy()\n",
    "\n",
    "interpolator = interp1d(wh_times, wh_vel_oversampled, fill_value='extrapolate')\n",
    "wh_vel = interpolator(times)\n",
    "\n",
    "plot_relative_wheel_positions_around_transitions(eids[0], wh_times, wh_pos, states_ibl_smooth, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (INCOMPLETE)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_state_runs(states, min_length=20):\n",
    "    \"\"\"\n",
    "    Find contiguous chunks of data with the same state.\n",
    "    \"\"\"\n",
    "    K = int(np.max(states) + 1)\n",
    "    state_snippets = [[] for _ in range(K)]\n",
    "    \n",
    "    buffer = 100\n",
    "    \n",
    "    i_beg = buffer\n",
    "    curr_state = states[i_beg]\n",
    "    curr_len = 1\n",
    "    for i in range(i_beg + 1, len(states) - buffer):\n",
    "        next_state = states[i]\n",
    "        if next_state != curr_state:\n",
    "            if curr_len >= min_length:\n",
    "                state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "            i_beg = i\n",
    "            curr_state = next_state\n",
    "            curr_len = 1\n",
    "        else:\n",
    "            curr_len += 1\n",
    "    if curr_len >= min_length:\n",
    "        state_snippets[curr_state].append(np.arange(i_beg, i))\n",
    "    return state_snippets\n",
    "\n",
    "def plot_paw_speed_around_transitions(eid, paw_x_vel, paw_y_vel, states, times, pre_window=(-0.25, 0), post_window=(0, 0.25), max_frame_distance=30):\n",
    "    \"\"\"\n",
    "    Plot relative paw speed around Still to Move and Move to Still transitions.\n",
    "    \"\"\"\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "    paw_speed = np.sqrt(paw_x_vel ** 2 + paw_y_vel ** 2)\n",
    "\n",
    "    state_snippets = extract_state_runs(states, min_length=20)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(state_snippets)):\n",
    "        for chunk in state_snippets[i]:\n",
    "            end_idx = chunk[-1]\n",
    "            for j in range(len(state_snippets)):\n",
    "                if i != j:\n",
    "                    for next_chunk in state_snippets[j]:\n",
    "                        start_idx = next_chunk[0]\n",
    "                        if 0 < start_idx - end_idx <= max_frame_distance:\n",
    "                            transitions.append((i, j, chunk, next_chunk, times[start_idx]))\n",
    "\n",
    "    # Filter transitions for Still to Move and Move to Still\n",
    "    filtered_transitions = [\n",
    "        (pre_state, post_state, chunk, next_chunk, transition_time)\n",
    "        for pre_state, post_state, chunk, next_chunk, transition_time in transitions\n",
    "        if (pre_state == 1 and post_state == 2) or (pre_state == 2 and post_state == 1)\n",
    "    ]\n",
    "\n",
    "    # Group transitions by (pre_state, post_state)\n",
    "    transition_groups = defaultdict(list)\n",
    "    for pre_state, post_state, _, _, transition_time in filtered_transitions:\n",
    "        transition_groups[(pre_state, post_state)].append(transition_time)\n",
    "\n",
    "    # Plot paw speeds for each transition group\n",
    "    for (pre_state, post_state), transition_times in transition_groups.items():\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        # Plot all transitions for this state pair\n",
    "        for transition_time in transition_times:\n",
    "            pre_mask = (times >= (transition_time + pre_window[0])) & (times <= (transition_time + pre_window[1]))\n",
    "            post_mask = (times >= (transition_time + post_window[0])) & (times <= (transition_time + post_window[1]))\n",
    "\n",
    "            if np.sum(pre_mask) > 0:\n",
    "                pre_times = times[pre_mask] - transition_time\n",
    "                pre_paw_speed = paw_speed[pre_mask]\n",
    "                relative_pre_paw_speed = pre_paw_speed\n",
    "                plt.plot(pre_times, relative_pre_paw_speed, alpha=0.5, color=cmap(pre_state - 1))\n",
    "\n",
    "            if np.sum(post_mask) > 0:\n",
    "                post_times = times[post_mask] - transition_time\n",
    "                post_paw_speed = paw_speed[post_mask]\n",
    "                relative_post_paw_speed = post_paw_speed\n",
    "                plt.plot(post_times, relative_post_paw_speed, alpha=0.5, color=cmap(post_state - 1))\n",
    "\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Relative Paw Speed')\n",
    "        plt.title(f'Relative Paw Speed Around Transition {state_labels[pre_state-1]} to {state_labels[post_state-1]}')\n",
    "        plt.legend([\n",
    "            f'{state_labels[pre_state-1]} (Pre-Transition)',\n",
    "            f'{state_labels[post_state-1]} (Post-Transition)'\n",
    "        ], loc='best')\n",
    "        plt.show()\n",
    "\n",
    "def plot_wheel_speed_around_transitions(eid, wh_times, wh_vel, states, times, pre_window=(-0.25, 0), post_window=(0, 0.25), max_frame_distance=30):\n",
    "    \"\"\"\n",
    "    Plot relative wheel speed around Still to Wheel Turn and Wheel Turn to Still transitions.\n",
    "    \"\"\"\n",
    "    state_labels = ['Still', 'Move', 'Wheel Turn', 'Groom']\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "    if len(wh_times) > len(wh_vel):\n",
    "        wh_times = wh_times[:len(wh_vel)]\n",
    "    elif len(wh_vel) > len(wh_times):\n",
    "        wh_vel = wh_vel[:len(wh_times)]\n",
    "\n",
    "    interpolator = interp1d(wh_times, wh_vel, fill_value='extrapolate')\n",
    "    wh_speed_resampled = interpolator(times)\n",
    "\n",
    "    state_snippets = extract_state_runs(states, min_length=20)\n",
    "\n",
    "    transitions = []\n",
    "\n",
    "    for i in range(len(state_snippets)):\n",
    "        for chunk in state_snippets[i]:\n",
    "            end_idx = chunk[-1]\n",
    "            for j in range(len(state_snippets)):\n",
    "                if i != j:\n",
    "                    for next_chunk in state_snippets[j]:\n",
    "                        start_idx = next_chunk[0]\n",
    "                        if 0 < start_idx - end_idx <= max_frame_distance:\n",
    "                            transitions.append((i, j, chunk, next_chunk, times[start_idx]))\n",
    "\n",
    "    # Filter transitions for Still to Wheel Turn and Wheel Turn to Still\n",
    "    filtered_transitions = [\n",
    "        (pre_state, post_state, chunk, next_chunk, transition_time)\n",
    "        for pre_state, post_state, chunk, next_chunk, transition_time in transitions\n",
    "        if (pre_state == 1 and post_state == 3) or (pre_state == 3 and post_state == 1)\n",
    "    ]\n",
    "\n",
    "    # Group transitions by (pre_state, post_state)\n",
    "    transition_groups = defaultdict(list)\n",
    "    for pre_state, post_state, _, _, transition_time in filtered_transitions:\n",
    "        transition_groups[(pre_state, post_state)].append(transition_time)\n",
    "\n",
    "    # Plot wheel speeds for each transition group\n",
    "    for (pre_state, post_state), transition_times in transition_groups.items():\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        for transition_time in transition_times:\n",
    "            pre_mask = (times >= (transition_time + pre_window[0])) & (times <= (transition_time + pre_window[1]))\n",
    "            post_mask = (times >= (transition_time + post_window[0])) & (times <= (transition_time + post_window[1]))\n",
    "\n",
    "            if np.sum(pre_mask) > 0:\n",
    "                pre_times = times[pre_mask] - transition_time\n",
    "                pre_wheel_speed = wh_speed_resampled[pre_mask]\n",
    "                relative_pre_wheel_speed = pre_wheel_speed\n",
    "                plt.plot(pre_times, relative_pre_wheel_speed, alpha=0.5, color=cmap(pre_state - 1))\n",
    "\n",
    "            if np.sum(post_mask) > 0:\n",
    "                post_times = times[post_mask] - transition_time\n",
    "                post_wheel_speed = wh_speed_resampled[post_mask]\n",
    "                relative_post_wheel_speed = post_wheel_speed\n",
    "                plt.plot(post_times, relative_post_wheel_speed, alpha=0.5, color=cmap(post_state - 1))\n",
    "\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Relative Wheel Speed')\n",
    "        plt.title(f'Relative Wheel Speed Around Transition {state_labels[pre_state-1]} to {state_labels[post_state-1]}')\n",
    "        plt.legend([\n",
    "            f'{state_labels[pre_state-1]} (Pre-Transition)',\n",
    "            f'{state_labels[post_state-1]} (Post-Transition)'\n",
    "        ], loc='best')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Session Loader Parameters\n",
    "l_thresh_smooth = 0.9\n",
    "view = 'left'\n",
    "paw = 'paw_r'\n",
    "\n",
    "# Load times\n",
    "sl = SessionLoader(one=one, eid=eid)\n",
    "sl.load_pose(likelihood_thr=l_thresh_smooth, views=[view])\n",
    "times = sl.pose[f'{view}Camera'].times.to_numpy()\n",
    "\n",
    "\n",
    "# Load marker data\n",
    "file = extract_marker_data(eid, l_thresh_smooth, view, paw, smooth=True)\n",
    "df = pd.read_csv(file)\n",
    "wh_vel = df['wheel_vel'].to_numpy()\n",
    "wh_speed = np.abs(wh_vel)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load marker data\n",
    "sl.load_wheel()\n",
    "wh_times = sl.wheel.times.to_numpy()\n",
    "wh_vel_oversampled = sl.wheel.velocity.to_numpy()\n",
    "\n",
    "# Resample wheel data at marker times\n",
    "interpolator = interp1d(wh_times, wh_vel_oversampled, fill_value='extrapolate')\n",
    "wh_vel = interpolator(times)\"\"\"\n",
    "\n",
    "plot_paw_speed_around_transitions(eid, paw_x_vel, paw_y_vel, states_ibl_smooth, times)\n",
    "plot_wheel_speed_around_transitions(eid, wh_times, wh_vel, states_ibl_smooth, times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
